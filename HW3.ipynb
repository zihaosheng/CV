{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "## HW3: Decision Tree and Random Forest\n",
    "In hw3, you need to implement decision tree and random forest by using only numpy, then train your implemented model by the provided dataset and test the performance with testing data\n",
    "\n",
    "Please note that only **NUMPY** can be used to implement your model, you will get no points by simply calling sklearn.tree.DecisionTreeClassifier"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install sklearn"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Load data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.datasets import load_breast_cancer\n",
    "import operator\n",
    "import re"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "['mean radius' 'mean texture' 'mean perimeter' 'mean area'\n 'mean smoothness' 'mean compactness' 'mean concavity'\n 'mean concave points' 'mean symmetry' 'mean fractal dimension'\n 'radius error' 'texture error' 'perimeter error' 'area error'\n 'smoothness error' 'compactness error' 'concavity error'\n 'concave points error' 'symmetry error' 'fractal dimension error'\n 'worst radius' 'worst texture' 'worst perimeter' 'worst area'\n 'worst smoothness' 'worst compactness' 'worst concavity'\n 'worst concave points' 'worst symmetry' 'worst fractal dimension']\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "data = load_breast_cancer()\n",
    "feature_names = data['feature_names']\n",
    "print(feature_names)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [],
   "source": [
    "x_train = pd.read_csv(\"x_train.csv\")\n",
    "y_train = pd.read_csv(\"y_train.csv\")\n",
    "x_test = pd.read_csv(\"x_test.csv\")\n",
    "y_test = pd.read_csv(\"y_test.csv\")\n",
    "# print(x_train.shape)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 1\n",
    "Gini Index or Entropy is often used for measuring the “best” splitting of the data. Please compute the Entropy and Gini Index of provided data. Please use the formula from [page 7 of hw3 slides](https://docs.google.com/presentation/d/1ish3jEr_6be0FK4kgOZa12nYAyJFh0P2LCNsNPOCiXo/edit#slide=id.g7703d1636d_0_21)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def gini(sequence):\n",
    "    element1 = np.argmax(np.bincount(sequence))\n",
    "    size = np.shape(sequence)[0]\n",
    "    result = 1 - ((sequence.count(element1)/size)**2+((size-sequence.count(element1))/size)**2)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "def entropy(sequence):\n",
    "    element1 = np.argmax(np.bincount(sequence))\n",
    "    size = np.shape(sequence)[0]\n",
    "    count1 = sequence.count(element1)\n",
    "    count2 = size-count1\n",
    "    if count1==0 or count2 == 0:\n",
    "        return 0\n",
    "    result = -(count1/size)*np.log2(count1/size)-(count2/size)*np.log2(count2/size)\n",
    "    return result"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# 1 = class 1,\n",
    "# 2 = class 2\n",
    "data = np.array([1,2,1,1,1,1,2,2,1,1,2])\n",
    "data = np.ones(6)\n",
    "a =list(data)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Gini of data is \", gini(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(\"Entropy of data is \", entropy(a))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 2\n",
    "Implement the Decision Tree algorithm (CART, Classification and Regression Trees) and trained the model by the given arguments, and print the accuracy score on the test data. You should implement two arguments for the Decision Tree algorithm\n",
    "1. **Criterion**: The function to measure the quality of a split. Your model should support “gini” for the Gini impurity and “entropy” for the information gain. \n",
    "2. **Max_depth**: The maximum depth of the tree. If Max_depth=None, then nodes are expanded until all leaves are pure. Max_depth=1 equals to split data once\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "outputs": [],
   "source": [
    "class DecisionTree():\n",
    "    def __init__(self, criterion='gini', max_depth=None):\n",
    "        self.criterion = criterion\n",
    "        self.max_depth = max_depth\n",
    "\n",
    "        self.DT = self.create_tree(x_train, y_train, max_depth)\n",
    "        self.prediction = self.predict_label(self.DT, x_test)\n",
    "        self.accuary = self.evaluation(self.prediction, y_test)\n",
    "\n",
    "        return None\n",
    "\n",
    "    def gini(self, sequence):\n",
    "        element1 = np.argmax(np.bincount(sequence))\n",
    "        size = np.shape(sequence)[0]\n",
    "        result = 1 - ((sequence.count(element1) / size) ** 2 + ((size - sequence.count(element1)) / size) ** 2)\n",
    "        return result\n",
    "\n",
    "    def entropy(self, sequence):\n",
    "        element1 = np.argmax(np.bincount(sequence))\n",
    "        size = np.shape(sequence)[0]\n",
    "        count1 = sequence.count(element1)\n",
    "        count2 = size - count1\n",
    "        if count1 == 0 or count2 == 0:\n",
    "            return 0\n",
    "        result = -(count1 / size) * np.log2(count1 / size) - (count2 / size) * np.log2(count2 / size)\n",
    "        return result\n",
    "\n",
    "    def find_threshold(self, x_data, y_data):\n",
    "        best_criterion = 100\n",
    "        best_attribute = 'bb'\n",
    "        best_thershold = 0\n",
    "        feature = list(x_data.columns)\n",
    "        for _ in feature:\n",
    "            column = x_data[_]\n",
    "            sorted_column = np.sort(column)\n",
    "            for i in range(column.shape[0] - 1):\n",
    "                average = (sorted_column[i] + sorted_column[i + 1]) / 2\n",
    "                left, right = list(), list()\n",
    "                for row in range(column.shape[0]):\n",
    "                    if column.iloc[row] <= average:\n",
    "                        left.append(y_data['0'].iloc[row])\n",
    "                    else:\n",
    "                        right.append(y_data['0'].iloc[row])\n",
    "                if self.criterion == 'gini':\n",
    "                    temp_criterion = len(left) / column.shape[0] * self.gini(left) + len(right) / column.shape[0] * self.gini(right)\n",
    "                    # print('gini: ', temp_criterion)\n",
    "                else:\n",
    "                    temp_criterion = len(left) / column.shape[0] * self.entropy(left) + len(right) / column.shape[0] * self.entropy(right)\n",
    "                    # print('not gini: ', temp_criterion)\n",
    "                if temp_criterion < best_criterion:\n",
    "                    # print('current best: ', temp_criterion)\n",
    "                    best_criterion = temp_criterion\n",
    "                    best_attribute = _\n",
    "                    best_thershold = average\n",
    "        left_child = x_data[x_data[best_attribute] <= best_thershold]\n",
    "        del left_child[best_attribute]\n",
    "        left_y = y_data[x_data[best_attribute] <= best_thershold]\n",
    "        right_child = x_data[x_data[best_attribute] > best_thershold]\n",
    "        del right_child[best_attribute]\n",
    "        right_y = y_data[x_data[best_attribute] > best_thershold]\n",
    "\n",
    "        return left_child, left_y, right_child, right_y, best_attribute, best_thershold,best_criterion, y_data.shape[0]\n",
    "\n",
    "    # 在dataSet中返回数目最多的类别标记\n",
    "    def majorityClass(self, dataSet):\n",
    "        counts = {}\n",
    "        labels = dataSet.iloc[:, -1]\n",
    "        for one in labels:\n",
    "            if one not in counts.keys():\n",
    "                counts[one] = 0\n",
    "            counts[one] += 1\n",
    "        sortedCounts = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return sortedCounts[0][0]\n",
    "\n",
    "    # %%\n",
    "    def create_tree(self, x_data, y_data, max_depth):\n",
    "        if 30 - len(x_data.columns) > self.max_depth:\n",
    "            return self.majorityClass(y_data)\n",
    "        if len(x_data.columns) == 1:\n",
    "            return self.majorityClass(y_data)\n",
    "        if len(set(y_data.iloc[:, -1])) == 1:\n",
    "            return y_data.iloc[0, -1]\n",
    "        left_child, left_y, right_child, right_y, bestAttribute, bestTh, bestCriterion, numofInstance = self.find_threshold(x_data, y_data)\n",
    "        decisionTree = {(bestAttribute,bestCriterion,numofInstance): {}}\n",
    "        print(decisionTree)\n",
    "        decisionTree[(bestAttribute,bestCriterion,numofInstance)]['<=' + str(bestTh)] = self.create_tree(left_child, left_y, max_depth)\n",
    "        decisionTree[(bestAttribute,bestCriterion,numofInstance)]['>' + str(bestTh)] = self.create_tree(right_child, right_y, max_depth)\n",
    "        return decisionTree\n",
    "\n",
    "    def classify(self,inputTree,testVec):\n",
    "        firstStr = list(inputTree)[0]\n",
    "        secondDict = inputTree[firstStr]\n",
    "        secondStr = list(secondDict)[0]\n",
    "        TH = float(re.findall(r\"\\d+\\.?\\d*\",secondStr)[0])\n",
    "        attrValue = testVec[firstStr[0]]\n",
    "        if attrValue <= TH:\n",
    "            key = '<=' + str(TH)\n",
    "        else:\n",
    "            key = '>' + str(TH)\n",
    "        valueOfFeat = secondDict[key]\n",
    "        if isinstance(valueOfFeat, dict):\n",
    "            classLabel = self.classify(valueOfFeat, testVec)\n",
    "        else: classLabel = valueOfFeat\n",
    "        return classLabel\n",
    "    def predict_label(self, tree, test):\n",
    "        predict = []\n",
    "        for i in range(test.shape[0]):\n",
    "            predictLable = self.classify(tree, test.iloc[i, :])\n",
    "            predict.append(predictLable)\n",
    "        return predict\n",
    "    def evaluation(self, predict, y):\n",
    "        right =0\n",
    "        for i in range(len(predict)):\n",
    "            if predict[i] == int(y.iloc[i]):\n",
    "                right += 1\n",
    "        print(right)\n",
    "        return right / len(predict)\n",
    "\n",
    "        "
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2.1\n",
    "Using Criterion=‘gini’, showing the accuracy score of test data by Max_depth=3 and Max_depth=10, respectively.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{('worst radius', 0.13485126330395825, 426): {}}\n",
      "{('worst concave points', 0.06702518547717266, 283): {}}\n",
      "{('area error', 0.011920190723051742, 251): {}}\n",
      "{('worst texture', 0.007559650366170559, 249): {}}\n{('mean radius', 0.0, 2): {}}\n",
      "{('worst texture', 0.24215686274509804, 32): {}}\n{('worst area', 0.2212121212121213, 15): {}}\n",
      "{('mean perimeter', 0.0, 17): {}}\n",
      "{('mean texture', 0.06314897223988139, 143): {}}\n{('mean concavity', 0.0, 11): {}}\n",
      "{('mean concave points', 0.015035854730511295, 132): {}}\n",
      "{('worst concavity', 0.010178117048346055, 131): {}}\n133\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "clf_depth3 = DecisionTree(criterion='gini', max_depth=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9300699300699301"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 71
    }
   ],
   "source": [
    "clf_depth3.accuary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{('worst radius', 0.13485126330395825, 426): {}}\n",
      "{('worst concave points', 0.06702518547717266, 283): {}}\n",
      "{('area error', 0.011920190723051742, 251): {}}\n",
      "{('worst texture', 0.007559650366170559, 249): {}}\n{('mean texture', 0.058823529411764705, 17): {}}\n{('mean radius', 0.0, 2): {}}\n{('mean radius', 0.0, 2): {}}\n",
      "{('worst texture', 0.24215686274509804, 32): {}}\n{('worst area', 0.2212121212121213, 15): {}}\n{('mean texture', 0.0, 11): {}}\n",
      "{('mean radius', 0.0, 4): {}}\n",
      "{('mean perimeter', 0.0, 17): {}}\n",
      "{('mean texture', 0.06314897223988139, 143): {}}\n{('mean concavity', 0.0, 11): {}}\n",
      "{('mean concave points', 0.015035854730511295, 132): {}}\n",
      "{('worst concavity', 0.010178117048346055, 131): {}}\n{('mean smoothness', 0.0, 3): {}}\n132\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "clf_depth10 = DecisionTree(criterion='gini', max_depth=10)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9230769230769231"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 73
    }
   ],
   "source": [
    "clf_depth10.accuary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 2.2\n",
    "Using Max_depth=3, showing the accuracy score of test data by Criterion=‘gini’ and Criterion=’entropy’, respectively.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf_gini = DecisionTree(criterion='gini', max_depth=3)\n",
    "clf_entropy = DecisionTree(criterion='entropy', max_depth=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Note: All of your accuracy scores should over 0.9\n",
    "- Note: You should get the same results when re-building the model with the same arguments,  no need to prune the trees\n",
    "- Hint: You can use the recursive method to build the nodes\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 3\n",
    "Plot the [feature importance](https://sefiks.com/2020/04/06/feature-importance-in-decision-trees/) of your Decision Tree model. You can get the feature importance by counting the feature used for splitting data.\n",
    "\n",
    "- You can simply plot the feature counts for building tree without normalize the importance\n",
    "\n",
    "![image](https://i2.wp.com/sefiks.com/wp-content/uploads/2020/04/c45-fi-results.jpg?w=481&ssl=1)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Question 4\n",
    "implement the Random Forest algorithm by using the CART you just implemented from question 2. You should implement two arguments for the Random Forest.\n",
    "\n",
    "1. **N_estimators**: The number of trees in the forest. \n",
    "2. **Max_features**: The number of random select features to consider when looking for the best split\n",
    "3. **Bootstrap**: Whether bootstrap samples are used when building tree\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "outputs": [],
   "source": [
    "from random import randrange"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [],
   "source": [
    "class RandomForest():\n",
    "    def __init__(self, n_estimators, max_features, bootstrap=True, criterion='gini', max_depth=None):\n",
    "        self.n_estimators = n_estimators\n",
    "        self.max_features = max_features\n",
    "        self.bootstrap = bootstrap\n",
    "        self.RM = self.create_forest(self.n_estimators, self.max_features, self.bootstrap)\n",
    "        self.prediction = self.predict_label(self.RM, x_test)\n",
    "        self.accuary = self.evaluation(self.prediction, y_test)\n",
    "        return None\n",
    "        # return accuracy\n",
    "    def gini(self, sequence):\n",
    "        if len(sequence)==0:\n",
    "            return 0\n",
    "        element1 = np.argmax(np.bincount(sequence))\n",
    "        size = np.shape(sequence)[0]\n",
    "        result = 1 - ((sequence.count(element1) / size) ** 2 + ((size - sequence.count(element1)) / size) ** 2)\n",
    "        return result\n",
    "    def create_forest(self,n_estimators,max_features,bootstrap):\n",
    "        tree_list = []\n",
    "        for i in range(n_estimators):\n",
    "            if bootstrap==True:\n",
    "                x_data,y_data = self.getsubsample(x_train,y_train)\n",
    "                DT = self.create_tree(max_features,x_data,y_data)\n",
    "            else:\n",
    "                DT = self.create_tree(max_features,x_train,y_train)\n",
    "            tree_list.append(DT)\n",
    "        return tree_list\n",
    "    # 在dataSet中返回数目最多的类别标记\n",
    "    def majorityClass(self, dataSet):\n",
    "        counts = {}\n",
    "        labels = dataSet.iloc[:, -1]\n",
    "        for one in labels:\n",
    "            if one not in counts.keys():\n",
    "                counts[one] = 0\n",
    "            counts[one] += 1\n",
    "        sortedCounts = sorted(counts.items(), key=operator.itemgetter(1), reverse=True)\n",
    "        return sortedCounts[0][0]\n",
    "    def create_tree(self,max_features,x_data,y_data):\n",
    "        if len(x_data.columns) == 1:\n",
    "            return self.majorityClass(y_data)\n",
    "        if len(set(y_data.iloc[:, -1])) == 1:\n",
    "            return y_data.iloc[0, -1]\n",
    "        left_child, left_y, right_child, right_y, bestAttribute, bestTh = self.find_threshold(x_data, y_data,max_features)\n",
    "        decisionTree = {bestAttribute: {}}\n",
    "        print(decisionTree)\n",
    "        decisionTree[bestAttribute]['<=' + str(bestTh)] = self.create_tree(max_features,left_child, left_y)\n",
    "        decisionTree[bestAttribute]['>' + str(bestTh)] = self.create_tree(max_features,right_child, right_y)\n",
    "        return decisionTree\n",
    "    def getsubsample(self,x_data,y_data):\n",
    "        x_columns = x_data.columns\n",
    "        y_columns = y_data.columns\n",
    "        subdataset_x = pd.DataFrame(columns=x_columns)\n",
    "        subdataset_y = pd.DataFrame(columns=y_columns)\n",
    "        len_data = x_data.shape[0]\n",
    "        while len(subdataset_x) < len_data:\n",
    "            index = randrange(x_data.shape[0]-1)\n",
    "            subdataset_x = subdataset_x.append(x_data.iloc[index,:])\n",
    "            subdataset_y = subdataset_y.append(y_data.iloc[index,:])\n",
    "        return subdataset_x,subdataset_y\n",
    "    def extract_feature(self,feature,max_feature):\n",
    "        subset = []\n",
    "        while len(subset)<max_feature:\n",
    "            index = randrange(len(feature)-1)\n",
    "            if feature[index] not in subset:\n",
    "                subset.append(feature[index])\n",
    "        return subset\n",
    "    def find_threshold(self, x_data, y_data,max_feature):\n",
    "        best_criterion = 100\n",
    "        best_attribute = 'bb'\n",
    "        best_thershold = 0\n",
    "        feature = list(x_data.columns)\n",
    "        feature = self.extract_feature(feature,max_feature)\n",
    "        for _ in feature:\n",
    "            column = x_data[_]\n",
    "            sorted_column = np.sort(column)\n",
    "            for i in range(column.shape[0] - 1):\n",
    "                average = (sorted_column[i] + sorted_column[i + 1]) / 2\n",
    "                left, right = list(), list()\n",
    "                for row in range(column.shape[0]):\n",
    "                    if column.iloc[row] <= average:\n",
    "                        left.append(y_data['0'].iloc[row])\n",
    "                    else:\n",
    "                        right.append(y_data['0'].iloc[row])\n",
    "                # print('length of left',len(left), 'right ', len(right))\n",
    "                temp_criterion = len(left) / column.shape[0] * self.gini(left) + len(right) / column.shape[0] * self.gini(right)\n",
    "                if temp_criterion < best_criterion:\n",
    "                    best_criterion = temp_criterion\n",
    "                    best_attribute = _\n",
    "                    best_thershold = average\n",
    "        left_child = x_data[x_data[best_attribute] <= best_thershold]\n",
    "        del left_child[best_attribute]\n",
    "        left_y = y_data[x_data[best_attribute] <= best_thershold]\n",
    "        right_child = x_data[x_data[best_attribute] > best_thershold]\n",
    "        del right_child[best_attribute]\n",
    "        right_y = y_data[x_data[best_attribute] > best_thershold]\n",
    "\n",
    "        return left_child, left_y, right_child, right_y, best_attribute, best_thershold\n",
    "    def classify(self,inputTree,testVec):\n",
    "        firstStr = list(inputTree)[0]\n",
    "        secondDict = inputTree[firstStr]\n",
    "        secondStr = list(secondDict)[0]\n",
    "        TH = float(re.findall(r\"\\d+\\.?\\d*\",secondStr)[0])\n",
    "        attrValue = testVec[firstStr]\n",
    "        if attrValue <= TH:\n",
    "            key = '<=' + str(TH)\n",
    "        else:\n",
    "            key = '>' + str(TH)\n",
    "        valueOfFeat = secondDict[key]\n",
    "        if isinstance(valueOfFeat, dict):\n",
    "            classLabel = self.classify(valueOfFeat, testVec)\n",
    "        else: classLabel = valueOfFeat\n",
    "        return classLabel\n",
    "    def predict_label(self, forest, test):\n",
    "        predict = []\n",
    "        for i in range(test.shape[0]):\n",
    "            daixuan = []\n",
    "            for j in range(self.n_estimators):\n",
    "                predictLable = self.classify(forest[j], test.iloc[i, :])\n",
    "                daixuan.append(predictLable)\n",
    "            element1 = np.argmax(np.bincount(daixuan))\n",
    "            predict.append(element1)\n",
    "        return predict\n",
    "    def evaluation(self, predict, y):\n",
    "        right =0\n",
    "        for i in range(len(predict)):\n",
    "            if predict[i] == int(y.iloc[i]):\n",
    "                right += 1\n",
    "        return right / len(predict)\n",
    "    \n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 4.1\n",
    "Using Criterion=‘gini’, Max_depth=None, Max_features=sqrt(n_features), showing the accuracy score of test data by n_estimators=10 and n_estimators=100, respectively.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'worst area': {}}\n",
      "{'worst concave points': {}}\n",
      "{'mean area': {}}\n",
      "{'worst symmetry': {}}\n{'worst perimeter': {}}\n",
      "{'perimeter error': {}}\n",
      "{'texture error': {}}\n{'area error': {}}\n{'area error': {}}\n{'mean concave points': {}}\n{'mean texture': {}}\n{'concave points error': {}}\n",
      "{'perimeter error': {}}\n{'mean texture': {}}\n",
      "{'mean concavity': {}}\n{'mean texture': {}}\n",
      "{'worst area': {}}\n",
      "{'worst concave points': {}}\n",
      "{'worst smoothness': {}}\n",
      "{'worst perimeter': {}}\n",
      "{'radius error': {}}\n",
      "{'worst texture': {}}\n{'mean concave points': {}}\n{'mean perimeter': {}}\n{'compactness error': {}}\n{'mean texture': {}}\n{'worst symmetry': {}}",
      "\n{'mean perimeter': {}}\n{'mean perimeter': {}}\n",
      "{'concavity error': {}}\n{'mean texture': {}}\n",
      "{'worst concavity': {}}\n",
      "{'mean concave points': {}}\n",
      "{'mean radius': {}}\n",
      "{'worst radius': {}}\n",
      "{'worst smoothness': {}}\n",
      "{'texture error': {}}\n",
      "{'worst area': {}}\n{'mean concavity': {}}\n{'area error': {}}\n{'mean symmetry': {}}\n",
      "{'worst perimeter': {}}\n",
      "{'worst radius': {}}\n{'worst smoothness': {}}\n{'mean compactness': {}}\n",
      "{'concavity error': {}}\n",
      "{'worst perimeter': {}}\n",
      "{'worst smoothness': {}}\n",
      "{'worst radius': {}}\n",
      "{'area error': {}}\n",
      "{'worst concavity': {}}\n{'compactness error': {}}\n{'worst concavity': {}}\n{'worst area': {}}\n",
      "{'mean concavity': {}}\n{'compactness error': {}}\n",
      "{'mean radius': {}}\n",
      "{'mean concave points': {}}\n",
      "{'worst perimeter': {}}\n",
      "{'worst radius': {}}\n",
      "{'worst concave points': {}}\n",
      "{'concavity error': {}}\n",
      "{'mean compactness': {}}\n{'area error': {}}\n{'concave points error': {}}\n{'texture error': {}}\n{'worst symmetry': {}}\n",
      "{'worst area': {}}\n{'worst compactness': {}}\n",
      "{'fractal dimension error': {}}\n{'worst perimeter': {}}\n{'mean perimeter': {}}\n{'radius error': {}}\n",
      "{'worst compactness': {}}\n{'perimeter error': {}}\n",
      "{'mean concave points': {}}\n",
      "{'mean area': {}}\n",
      "{'worst area': {}}\n",
      "{'area error': {}}\n",
      "{'worst smoothness': {}}\n",
      "{'concavity error': {}}\n",
      "{'worst texture': {}}\n{'worst perimeter': {}}\n{'fractal dimension error': {}}\n{'mean texture': {}}\n",
      "{'worst texture': {}}\n{'radius error': {}}\n{'worst concavity': {}}\n{'mean area': {}}\n",
      "{'worst concavity': {}}\n",
      "{'worst perimeter': {}}\n",
      "{'worst perimeter': {}}\n",
      "{'worst concave points': {}}\n",
      "{'symmetry error': {}}\n",
      "{'perimeter error': {}}\n",
      "{'texture error': {}}\n{'worst area': {}}\n{'mean concavity': {}}\n{'worst radius': {}}\n",
      "{'worst concave points': {}}\n{'mean texture': {}}\n",
      "{'worst compactness': {}}\n{'mean area': {}}\n{'mean radius': {}}\n{'mean smoothness': {}}\n{'radius error': {}}\n",
      "{'concavity error': {}}\n",
      "{'worst area': {}}\n{'mean perimeter': {}}\n",
      "{'worst radius': {}}\n",
      "{'worst symmetry': {}}\n",
      "{'worst concave points': {}}\n",
      "{'area error': {}}\n",
      "{'mean concavity': {}}\n",
      "{'concavity error': {}}\n{'mean compactness': {}}\n",
      "{'worst compactness': {}}\n{'concavity error': {}}\n{'mean symmetry': {}}\n{'symmetry error': {}}\n{'mean texture': {}}\n",
      "{'mean concave points': {}}\n",
      "{'worst perimeter': {}}\n{'mean texture': {}}\n",
      "{'worst concave points': {}}\n",
      "{'smoothness error': {}}\n",
      "{'worst area': {}}\n",
      "{'worst texture': {}}\n",
      "{'worst symmetry': {}}\n{'perimeter error': {}}\n{'worst smoothness': {}}\n{'worst concavity': {}}\n{'worst perimeter': {}}\n{'worst compactness': {}}\n{'mean compactness': {}}\n",
      "{'worst area': {}}\n{'worst smoothness': {}}\n{'smoothness error': {}}\n",
      "{'mean concavity': {}}\n{'worst radius': {}}\n{'texture error': {}}\n",
      "{'worst texture': {}}\n{'fractal dimension error': {}}\n",
      "{'mean radius': {}}\n",
      "{'mean concavity': {}}\n",
      "{'mean concave points': {}}\n",
      "{'radius error': {}}\n",
      "{'worst radius': {}}\n",
      "{'worst concavity': {}}\n{'worst texture': {}}\n{'mean area': {}}\n{'mean smoothness': {}}\n{'mean fractal dimension': {}}\n{'worst concave points': {}}\n",
      "{'worst concave points': {}}\n{'area error': {}}\n{'worst symmetry': {}}\n",
      "{'worst concavity': {}}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "clf_10tree = RandomForest(n_estimators=10, max_features=np.sqrt(x_train.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "outputs": [
    {
     "data": {
      "text/plain": "0.9440559440559441"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 78
    }
   ],
   "source": [
    "# clf_10tree.predict_label(clf_10tree, x_test)\n",
    "# print(clf_10tree.evaluation(clf_10tree.prediction, y_test))\n",
    "clf_10tree.accuary"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "{'worst perimeter': {}}\n",
      "{'mean concave points': {}}\n",
      "{'mean symmetry': {}}\n",
      "{'perimeter error': {}}\n",
      "{'worst symmetry': {}}\n{'worst area': {}}\n",
      "{'worst texture': {}}\n{'worst compactness': {}}\n",
      "{'smoothness error': {}}\n{'mean area': {}}\n{'concave points error': {}}\n",
      "{'area error': {}}\n",
      "{'mean texture': {}}\n",
      "{'texture error': {}}\n{'mean symmetry': {}}\n",
      "{'worst area': {}}\n",
      "{'worst concave points': {}}\n",
      "{'worst area': {}}\n",
      "{'worst texture': {}}\n",
      "{'mean area': {}}\n",
      "{'radius error': {}}\n{'worst concavity': {}}\n{'perimeter error': {}}\n{'mean texture': {}}\n{'texture error': {}}\n{'texture error': {}}\n",
      "{'worst concavity': {}}\n",
      "{'perimeter error': {}}\n{'mean texture': {}}\n",
      "{'concave points error': {}}\n",
      "{'mean perimeter': {}}\n",
      "{'worst radius': {}}\n",
      "{'mean concave points': {}}\n",
      "{'worst texture': {}}\n{'mean texture': {}}\n{'worst area': {}}\n",
      "{'mean symmetry': {}}\n{'mean texture': {}}\n{'worst texture': {}}\n",
      "{'worst concave points': {}}\n",
      "{'area error': {}}\n",
      "{'worst symmetry': {}}\n{'mean texture': {}}\n",
      "{'worst concave points': {}}\n",
      "{'worst texture': {}}\n",
      "{'worst radius': {}}\n",
      "{'area error': {}}\n",
      "{'worst perimeter': {}}\n{'concavity error': {}}\n{'symmetry error': {}}\n{'mean texture': {}}\n{'mean symmetry': {}}\n",
      "{'concavity error': {}}\n",
      "{'texture error': {}}\n",
      "{'mean concave points': {}}\n",
      "{'mean radius': {}}\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "clf_100tree = RandomForest(n_estimators=100, max_features=np.sqrt(x_train.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": true
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf_100tree.accuracy"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Question 4.2\n",
    "Using Criterion=‘gini’, Max_depth=None, N_estimators=10, showing the accuracy score of test data by Max_features=sqrt(n_features) and Max_features=n_features, respectively.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "clf_all_features = RandomForest(n_estimators=10, max_features=np.sqrt(x_train.shape[1]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "\n",
    "clf_random_features = RandomForest(n_estimators=10, max_features=x_train.shape[1])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "- Note: Use majority votes to get the final prediction, you may get slightly different results when re-building the random forest model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Supplementary\n",
    "If you have trouble to implement this homework, TA strongly recommend watching [this video](https://www.youtube.com/watch?v=LDRbO9a6XPU), which explains Decision Tree model clearly. But don't copy code from any resources, try to finish this homework by yourself! "
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}