{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.6"
    },
    "colab": {
      "name": "train.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "yVh4aZJBXUdo",
        "colab_type": "code",
        "outputId": "4b708e84-cb45-4a30-8c1b-4677f18c9c8a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SmTAH95jXsnP",
        "colab_type": "text"
      },
      "source": [
        "### nets.CSPdarknet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "37HotMBvXuIb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn.functional as F\n",
        "import torch.nn as nn\n",
        "import math\n",
        "from collections import OrderedDict\n",
        "\n",
        "#-------------------------------------------------#\n",
        "#   MISH激活函数\n",
        "#-------------------------------------------------#\n",
        "class Mish(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Mish, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x * torch.tanh(F.softplus(x))\n",
        "\n",
        "#-------------------------------------------------#\n",
        "#   卷积块\n",
        "#   CONV+BATCHNORM+MISH\n",
        "#-------------------------------------------------#\n",
        "class BasicConv(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, kernel_size, stride=1):\n",
        "        super(BasicConv, self).__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, kernel_size//2, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(out_channels)\n",
        "        self.activation = Mish()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv(x)\n",
        "        x = self.bn(x)\n",
        "        x = self.activation(x)\n",
        "        return x\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   CSPdarknet的结构块的组成部分\n",
        "#   内部堆叠的残差块\n",
        "#---------------------------------------------------#\n",
        "class Resblock(nn.Module):\n",
        "    def __init__(self, channels, hidden_channels=None, residual_activation=nn.Identity()):\n",
        "        super(Resblock, self).__init__()\n",
        "\n",
        "        if hidden_channels is None:\n",
        "            hidden_channels = channels\n",
        "\n",
        "        self.block = nn.Sequential(\n",
        "            BasicConv(channels, hidden_channels, 1),\n",
        "            BasicConv(hidden_channels, channels, 3)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return x + self.block(x)\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   CSPdarknet的结构块\n",
        "#   存在一个大残差边\n",
        "#   这个大残差边绕过了很多的残差结构\n",
        "#---------------------------------------------------#\n",
        "class Resblock_body(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels, num_blocks, first):\n",
        "        super(Resblock_body, self).__init__()\n",
        "\n",
        "        self.downsample_conv = BasicConv(in_channels, out_channels, 3, stride=2)\n",
        "\n",
        "        if first:\n",
        "            self.split_conv0 = BasicConv(out_channels, out_channels, 1)\n",
        "            self.split_conv1 = BasicConv(out_channels, out_channels, 1)  \n",
        "            self.blocks_conv = nn.Sequential(\n",
        "                Resblock(channels=out_channels, hidden_channels=out_channels//2),\n",
        "                BasicConv(out_channels, out_channels, 1)\n",
        "            )\n",
        "            self.concat_conv = BasicConv(out_channels*2, out_channels, 1)\n",
        "        else:\n",
        "            self.split_conv0 = BasicConv(out_channels, out_channels//2, 1)\n",
        "            self.split_conv1 = BasicConv(out_channels, out_channels//2, 1)\n",
        "\n",
        "            self.blocks_conv = nn.Sequential(\n",
        "                *[Resblock(out_channels//2) for _ in range(num_blocks)],\n",
        "                BasicConv(out_channels//2, out_channels//2, 1)\n",
        "            )\n",
        "            self.concat_conv = BasicConv(out_channels, out_channels, 1)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.downsample_conv(x)\n",
        "\n",
        "        x0 = self.split_conv0(x)\n",
        "\n",
        "        x1 = self.split_conv1(x)\n",
        "        x1 = self.blocks_conv(x1)\n",
        "\n",
        "        x = torch.cat([x1, x0], dim=1)\n",
        "        x = self.concat_conv(x)\n",
        "\n",
        "        return x\n",
        "\n",
        "class CSPDarkNet(nn.Module):\n",
        "    def __init__(self, layers):\n",
        "        super(CSPDarkNet, self).__init__()\n",
        "        self.inplanes = 32\n",
        "        self.conv1 = BasicConv(3, self.inplanes, kernel_size=3, stride=1)\n",
        "        self.feature_channels = [64, 128, 256, 512, 1024]\n",
        "\n",
        "        self.stages = nn.ModuleList([\n",
        "            Resblock_body(self.inplanes, self.feature_channels[0], layers[0], first=True),\n",
        "            Resblock_body(self.feature_channels[0], self.feature_channels[1], layers[1], first=False),\n",
        "            Resblock_body(self.feature_channels[1], self.feature_channels[2], layers[2], first=False),\n",
        "            Resblock_body(self.feature_channels[2], self.feature_channels[3], layers[3], first=False),\n",
        "            Resblock_body(self.feature_channels[3], self.feature_channels[4], layers[4], first=False)\n",
        "        ])\n",
        "\n",
        "        self.num_features = 1\n",
        "        # 进行权值初始化\n",
        "        for m in self.modules():\n",
        "            if isinstance(m, nn.Conv2d):\n",
        "                n = m.kernel_size[0] * m.kernel_size[1] * m.out_channels\n",
        "                m.weight.data.normal_(0, math.sqrt(2. / n))\n",
        "            elif isinstance(m, nn.BatchNorm2d):\n",
        "                m.weight.data.fill_(1)\n",
        "                m.bias.data.zero_()\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "\n",
        "        x = self.stages[0](x)\n",
        "        x = self.stages[1](x)\n",
        "        out3 = self.stages[2](x)\n",
        "        out4 = self.stages[3](out3)\n",
        "        out5 = self.stages[4](out4)\n",
        "\n",
        "        return out3, out4, out5\n",
        "\n",
        "def darknet53(pretrained, **kwargs):\n",
        "    model = CSPDarkNet([1, 2, 8, 8, 4])\n",
        "    if pretrained:\n",
        "        if isinstance(pretrained, str):\n",
        "            model.load_state_dict(torch.load(pretrained))\n",
        "        else:\n",
        "            raise Exception(\"darknet request a pretrained path. got [{}]\".format(pretrained))\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R1y2T0x7Xn1A",
        "colab_type": "text"
      },
      "source": [
        "### net.yolo4"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "clG-i7C9Xlyd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from collections import OrderedDict\n",
        "# from nets.CSPdarknet import darknet53\n",
        "\n",
        "def conv2d(filter_in, filter_out, kernel_size, stride=1):\n",
        "    pad = (kernel_size - 1) // 2 if kernel_size else 0\n",
        "    return nn.Sequential(OrderedDict([\n",
        "        (\"conv\", nn.Conv2d(filter_in, filter_out, kernel_size=kernel_size, stride=stride, padding=pad, bias=False)),\n",
        "        (\"bn\", nn.BatchNorm2d(filter_out)),\n",
        "        (\"relu\", nn.LeakyReLU(0.1)),\n",
        "    ]))\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   SPP结构，利用不同大小的池化核进行池化\n",
        "#   池化后堆叠\n",
        "#---------------------------------------------------#\n",
        "class SpatialPyramidPooling(nn.Module):\n",
        "    def __init__(self, pool_sizes=[5, 9, 13]):\n",
        "        super(SpatialPyramidPooling, self).__init__()\n",
        "\n",
        "        self.maxpools = nn.ModuleList([nn.MaxPool2d(pool_size, 1, pool_size//2) for pool_size in pool_sizes])\n",
        "\n",
        "    def forward(self, x):\n",
        "        features = [maxpool(x) for maxpool in self.maxpools[::-1]]\n",
        "        features = torch.cat(features + [x], dim=1)\n",
        "\n",
        "        return features\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   卷积 + 上采样\n",
        "#---------------------------------------------------#\n",
        "class Upsample(nn.Module):\n",
        "    def __init__(self, in_channels, out_channels):\n",
        "        super(Upsample, self).__init__()\n",
        "\n",
        "        self.upsample = nn.Sequential(\n",
        "            conv2d(in_channels, out_channels, 1),\n",
        "            nn.Upsample(scale_factor=2, mode='nearest')\n",
        "        )\n",
        "\n",
        "    def forward(self, x,):\n",
        "        x = self.upsample(x)\n",
        "        return x\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   三次卷积块\n",
        "#---------------------------------------------------#\n",
        "def make_three_conv(filters_list, in_filters):\n",
        "    m = nn.Sequential(\n",
        "        conv2d(in_filters, filters_list[0], 1),\n",
        "        conv2d(filters_list[0], filters_list[1], 3),\n",
        "        conv2d(filters_list[1], filters_list[0], 1),\n",
        "    )\n",
        "    return m\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   五次卷积块\n",
        "#---------------------------------------------------#\n",
        "def make_five_conv(filters_list, in_filters):\n",
        "    m = nn.Sequential(\n",
        "        conv2d(in_filters, filters_list[0], 1),\n",
        "        conv2d(filters_list[0], filters_list[1], 3),\n",
        "        conv2d(filters_list[1], filters_list[0], 1),\n",
        "        conv2d(filters_list[0], filters_list[1], 3),\n",
        "        conv2d(filters_list[1], filters_list[0], 1),\n",
        "    )\n",
        "    return m\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   最后获得yolov4的输出\n",
        "#---------------------------------------------------#\n",
        "def yolo_head(filters_list, in_filters):\n",
        "    m = nn.Sequential(\n",
        "        conv2d(in_filters, filters_list[0], 3),\n",
        "        nn.Conv2d(filters_list[0], filters_list[1], 1),\n",
        "    )\n",
        "    return m\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   yolo_body\n",
        "#---------------------------------------------------#\n",
        "class YoloBody(nn.Module):\n",
        "    def __init__(self, num_anchors, num_classes):\n",
        "        super(YoloBody, self).__init__()\n",
        "        #  backbone\n",
        "        self.backbone = darknet53(None)\n",
        "\n",
        "        self.conv1 = make_three_conv([512,1024],1024)\n",
        "        self.SPP = SpatialPyramidPooling()\n",
        "        self.conv2 = make_three_conv([512,1024],2048)\n",
        "\n",
        "        self.upsample1 = Upsample(512,256)\n",
        "        self.conv_for_P4 = conv2d(512,256,1)\n",
        "        self.make_five_conv1 = make_five_conv([256, 512],512)\n",
        "\n",
        "        self.upsample2 = Upsample(256,128)\n",
        "        self.conv_for_P3 = conv2d(256,128,1)\n",
        "        self.make_five_conv2 = make_five_conv([128, 256],256)\n",
        "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
        "        # 4+1+num_classes\n",
        "        final_out_filter2 = num_anchors * (5 + num_classes)\n",
        "        self.yolo_head3 = yolo_head([256, final_out_filter2],128)\n",
        "\n",
        "        self.down_sample1 = conv2d(128,256,3,stride=2)\n",
        "        self.make_five_conv3 = make_five_conv([256, 512],512)\n",
        "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
        "        final_out_filter1 =  num_anchors * (5 + num_classes)\n",
        "        self.yolo_head2 = yolo_head([512, final_out_filter1],256)\n",
        "\n",
        "\n",
        "        self.down_sample2 = conv2d(256,512,3,stride=2)\n",
        "        self.make_five_conv4 = make_five_conv([512, 1024],1024)\n",
        "        # 3*(5+num_classes)=3*(5+20)=3*(4+1+20)=75\n",
        "        final_out_filter0 =  num_anchors * (5 + num_classes)\n",
        "        self.yolo_head1 = yolo_head([1024, final_out_filter0],512)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        #  backbone\n",
        "        x2, x1, x0 = self.backbone(x)\n",
        "\n",
        "        P5 = self.conv1(x0)\n",
        "        P5 = self.SPP(P5)\n",
        "        P5 = self.conv2(P5)\n",
        "\n",
        "        P5_upsample = self.upsample1(P5)\n",
        "        P4 = self.conv_for_P4(x1)\n",
        "        P4 = torch.cat([P4,P5_upsample],axis=1)\n",
        "        P4 = self.make_five_conv1(P4)\n",
        "\n",
        "        P4_upsample = self.upsample2(P4)\n",
        "        P3 = self.conv_for_P3(x2)\n",
        "        P3 = torch.cat([P3,P4_upsample],axis=1)\n",
        "        P3 = self.make_five_conv2(P3)\n",
        "\n",
        "        P3_downsample = self.down_sample1(P3)\n",
        "        P4 = torch.cat([P3_downsample,P4],axis=1)\n",
        "        P4 = self.make_five_conv3(P4)\n",
        "\n",
        "        P4_downsample = self.down_sample2(P4)\n",
        "        P5 = torch.cat([P4_downsample,P5],axis=1)\n",
        "        P5 = self.make_five_conv4(P5)\n",
        "\n",
        "        out2 = self.yolo_head3(P3)\n",
        "        out1 = self.yolo_head2(P4)\n",
        "        out0 = self.yolo_head1(P5)\n",
        "\n",
        "        return out0, out1, out2\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "04yUu5eiYBI7",
        "colab_type": "text"
      },
      "source": [
        "### utils.utils"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNBN0ATiYEkS",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from __future__ import division\n",
        "import os\n",
        "import math\n",
        "import time\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from PIL import Image, ImageDraw, ImageFont\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "class DecodeBox(nn.Module):\n",
        "    def __init__(self, anchors, num_classes, img_size):\n",
        "        super(DecodeBox, self).__init__()\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = len(anchors)\n",
        "        self.num_classes = num_classes\n",
        "        self.bbox_attrs = 5 + num_classes\n",
        "        self.img_size = img_size\n",
        "\n",
        "    def forward(self, input):\n",
        "        # input为bs,3*(1+4+num_classes),13,13\n",
        "\n",
        "        # 一共多少张图片\n",
        "        batch_size = input.size(0)\n",
        "        # 13，13\n",
        "        input_height = input.size(2)\n",
        "        input_width = input.size(3)\n",
        "\n",
        "        # 计算步长\n",
        "        # 每一个特征点对应原来的图片上多少个像素点\n",
        "        # 如果特征层为13x13的话，一个特征点就对应原来的图片上的32个像素点\n",
        "        # 416/13 = 32\n",
        "        stride_h = self.img_size[1] / input_height\n",
        "        stride_w = self.img_size[0] / input_width\n",
        "\n",
        "        # 把先验框的尺寸调整成特征层大小的形式\n",
        "        # 计算出先验框在特征层上对应的宽高\n",
        "        scaled_anchors = [(anchor_width / stride_w, anchor_height / stride_h) for anchor_width, anchor_height in self.anchors]\n",
        "\n",
        "        # bs,3*(5+num_classes),13,13 -> bs,3,13,13,(5+num_classes)\n",
        "        prediction = input.view(batch_size, self.num_anchors,\n",
        "                                self.bbox_attrs, input_height, input_width).permute(0, 1, 3, 4, 2).contiguous()\n",
        "\n",
        "        # 先验框的中心位置的调整参数\n",
        "        x = torch.sigmoid(prediction[..., 0])  \n",
        "        y = torch.sigmoid(prediction[..., 1])\n",
        "        # 先验框的宽高调整参数\n",
        "        w = prediction[..., 2]  # Width\n",
        "        h = prediction[..., 3]  # Height\n",
        "\n",
        "        # 获得置信度，是否有物体\n",
        "        conf = torch.sigmoid(prediction[..., 4])\n",
        "        # 种类置信度\n",
        "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.\n",
        "\n",
        "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
        "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
        "\n",
        "        # 生成网格，先验框中心，网格左上角 batch_size,3,13,13\n",
        "        grid_x = torch.linspace(0, input_width - 1, input_width).repeat(input_width, 1).repeat(\n",
        "            batch_size * self.num_anchors, 1, 1).view(x.shape).type(FloatTensor)\n",
        "        grid_y = torch.linspace(0, input_height - 1, input_height).repeat(input_height, 1).t().repeat(\n",
        "            batch_size * self.num_anchors, 1, 1).view(y.shape).type(FloatTensor)\n",
        "\n",
        "        # 生成先验框的宽高\n",
        "        anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))\n",
        "        anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))\n",
        "        anchor_w = anchor_w.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(w.shape)\n",
        "        anchor_h = anchor_h.repeat(batch_size, 1).repeat(1, 1, input_height * input_width).view(h.shape)\n",
        "        \n",
        "        # 计算调整后的先验框中心与宽高\n",
        "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
        "        pred_boxes[..., 0] = x.data + grid_x\n",
        "        pred_boxes[..., 1] = y.data + grid_y\n",
        "        pred_boxes[..., 2] = torch.exp(w.data) * anchor_w\n",
        "        pred_boxes[..., 3] = torch.exp(h.data) * anchor_h\n",
        "\n",
        "        # fig = plt.figure()\n",
        "        # ax = fig.add_subplot(121)\n",
        "        # if input_height==13:\n",
        "        #     plt.ylim(0,13)\n",
        "        #     plt.xlim(0,13)\n",
        "        # elif input_height==26:\n",
        "        #     plt.ylim(0,26)\n",
        "        #     plt.xlim(0,26)\n",
        "        # elif input_height==52:\n",
        "        #     plt.ylim(0,52)\n",
        "        #     plt.xlim(0,52)\n",
        "        # plt.scatter(grid_x.cpu(),grid_y.cpu())\n",
        "\n",
        "        # anchor_left = grid_x - anchor_w/2 \n",
        "        # anchor_top = grid_y - anchor_h/2 \n",
        "\n",
        "        # rect1 = plt.Rectangle([anchor_left[0,0,5,5],anchor_top[0,0,5,5]],anchor_w[0,0,5,5],anchor_h[0,0,5,5],color=\"r\",fill=False)\n",
        "        # rect2 = plt.Rectangle([anchor_left[0,1,5,5],anchor_top[0,1,5,5]],anchor_w[0,1,5,5],anchor_h[0,1,5,5],color=\"r\",fill=False)\n",
        "        # rect3 = plt.Rectangle([anchor_left[0,2,5,5],anchor_top[0,2,5,5]],anchor_w[0,2,5,5],anchor_h[0,2,5,5],color=\"r\",fill=False)\n",
        "\n",
        "        # ax.add_patch(rect1)\n",
        "        # ax.add_patch(rect2)\n",
        "        # ax.add_patch(rect3)\n",
        "\n",
        "        # ax = fig.add_subplot(122)\n",
        "        # if input_height==13:\n",
        "        #     plt.ylim(0,13)\n",
        "        #     plt.xlim(0,13)\n",
        "        # elif input_height==26:\n",
        "        #     plt.ylim(0,26)\n",
        "        #     plt.xlim(0,26)\n",
        "        # elif input_height==52:\n",
        "        #     plt.ylim(0,52)\n",
        "        #     plt.xlim(0,52)\n",
        "        # plt.scatter(grid_x.cpu(),grid_y.cpu())\n",
        "        # plt.scatter(pred_boxes[0,:,5,5,0].cpu(),pred_boxes[0,:,5,5,1].cpu(),c='r')\n",
        "\n",
        "        # pre_left = pred_boxes[...,0] - pred_boxes[...,2]/2 \n",
        "        # pre_top = pred_boxes[...,1] - pred_boxes[...,3]/2 \n",
        "\n",
        "        # rect1 = plt.Rectangle([pre_left[0,0,5,5],pre_top[0,0,5,5]],pred_boxes[0,0,5,5,2],pred_boxes[0,0,5,5,3],color=\"r\",fill=False)\n",
        "        # rect2 = plt.Rectangle([pre_left[0,1,5,5],pre_top[0,1,5,5]],pred_boxes[0,1,5,5,2],pred_boxes[0,1,5,5,3],color=\"r\",fill=False)\n",
        "        # rect3 = plt.Rectangle([pre_left[0,2,5,5],pre_top[0,2,5,5]],pred_boxes[0,2,5,5,2],pred_boxes[0,2,5,5,3],color=\"r\",fill=False)\n",
        "\n",
        "        # ax.add_patch(rect1)\n",
        "        # ax.add_patch(rect2)\n",
        "        # ax.add_patch(rect3)\n",
        "\n",
        "        # plt.show()\n",
        "        # 用于将输出调整为相对于416x416的大小\n",
        "        _scale = torch.Tensor([stride_w, stride_h] * 2).type(FloatTensor)\n",
        "        output = torch.cat((pred_boxes.view(batch_size, -1, 4) * _scale,\n",
        "                            conf.view(batch_size, -1, 1), pred_cls.view(batch_size, -1, self.num_classes)), -1)\n",
        "        return output.data\n",
        "        \n",
        "def letterbox_image(image, size):\n",
        "    iw, ih = image.size\n",
        "    w, h = size\n",
        "    scale = min(w/iw, h/ih)\n",
        "    nw = int(iw*scale)\n",
        "    nh = int(ih*scale)\n",
        "\n",
        "    image = image.resize((nw,nh), Image.BICUBIC)\n",
        "    new_image = Image.new('RGB', size, (128,128,128))\n",
        "    new_image.paste(image, ((w-nw)//2, (h-nh)//2))\n",
        "    return new_image\n",
        "\n",
        "def yolo_correct_boxes(top, left, bottom, right, input_shape, image_shape):\n",
        "    new_shape = image_shape*np.min(input_shape/image_shape)\n",
        "\n",
        "    offset = (input_shape-new_shape)/2./input_shape\n",
        "    scale = input_shape/new_shape\n",
        "\n",
        "    box_yx = np.concatenate(((top+bottom)/2,(left+right)/2),axis=-1)/input_shape\n",
        "    box_hw = np.concatenate((bottom-top,right-left),axis=-1)/input_shape\n",
        "\n",
        "    box_yx = (box_yx - offset) * scale\n",
        "    box_hw *= scale\n",
        "\n",
        "    box_mins = box_yx - (box_hw / 2.)\n",
        "    box_maxes = box_yx + (box_hw / 2.)\n",
        "    boxes =  np.concatenate([\n",
        "        box_mins[:, 0:1],\n",
        "        box_mins[:, 1:2],\n",
        "        box_maxes[:, 0:1],\n",
        "        box_maxes[:, 1:2]\n",
        "    ],axis=-1)\n",
        "    print(np.shape(boxes))\n",
        "    boxes *= np.concatenate([image_shape, image_shape],axis=-1)\n",
        "    return boxes\n",
        "\n",
        "def bbox_iou(box1, box2, x1y1x2y2=True):\n",
        "    \"\"\"\n",
        "        计算IOU\n",
        "    \"\"\"\n",
        "    if not x1y1x2y2:\n",
        "        b1_x1, b1_x2 = box1[:, 0] - box1[:, 2] / 2, box1[:, 0] + box1[:, 2] / 2\n",
        "        b1_y1, b1_y2 = box1[:, 1] - box1[:, 3] / 2, box1[:, 1] + box1[:, 3] / 2\n",
        "        b2_x1, b2_x2 = box2[:, 0] - box2[:, 2] / 2, box2[:, 0] + box2[:, 2] / 2\n",
        "        b2_y1, b2_y2 = box2[:, 1] - box2[:, 3] / 2, box2[:, 1] + box2[:, 3] / 2\n",
        "    else:\n",
        "        b1_x1, b1_y1, b1_x2, b1_y2 = box1[:, 0], box1[:, 1], box1[:, 2], box1[:, 3]\n",
        "        b2_x1, b2_y1, b2_x2, b2_y2 = box2[:, 0], box2[:, 1], box2[:, 2], box2[:, 3]\n",
        "\n",
        "    inter_rect_x1 = torch.max(b1_x1, b2_x1)\n",
        "    inter_rect_y1 = torch.max(b1_y1, b2_y1)\n",
        "    inter_rect_x2 = torch.min(b1_x2, b2_x2)\n",
        "    inter_rect_y2 = torch.min(b1_y2, b2_y2)\n",
        "\n",
        "    inter_area = torch.clamp(inter_rect_x2 - inter_rect_x1 + 1, min=0) * \\\n",
        "                 torch.clamp(inter_rect_y2 - inter_rect_y1 + 1, min=0)\n",
        "                 \n",
        "    b1_area = (b1_x2 - b1_x1 + 1) * (b1_y2 - b1_y1 + 1)\n",
        "    b2_area = (b2_x2 - b2_x1 + 1) * (b2_y2 - b2_y1 + 1)\n",
        "\n",
        "    iou = inter_area / (b1_area + b2_area - inter_area + 1e-16)\n",
        "\n",
        "    return iou\n",
        "\n",
        "\n",
        "def non_max_suppression(prediction, num_classes, conf_thres=0.5, nms_thres=0.4):\n",
        "    # 求左上角和右下角\n",
        "    box_corner = prediction.new(prediction.shape)\n",
        "    box_corner[:, :, 0] = prediction[:, :, 0] - prediction[:, :, 2] / 2\n",
        "    box_corner[:, :, 1] = prediction[:, :, 1] - prediction[:, :, 3] / 2\n",
        "    box_corner[:, :, 2] = prediction[:, :, 0] + prediction[:, :, 2] / 2\n",
        "    box_corner[:, :, 3] = prediction[:, :, 1] + prediction[:, :, 3] / 2\n",
        "    prediction[:, :, :4] = box_corner[:, :, :4]\n",
        "\n",
        "    output = [None for _ in range(len(prediction))]\n",
        "    for image_i, image_pred in enumerate(prediction):\n",
        "        # 利用置信度进行第一轮筛选\n",
        "        conf_mask = (image_pred[:, 4] >= conf_thres).squeeze()\n",
        "        image_pred = image_pred[conf_mask]\n",
        "\n",
        "        if not image_pred.size(0):\n",
        "            continue\n",
        "\n",
        "        # 获得种类及其置信度\n",
        "        class_conf, class_pred = torch.max(image_pred[:, 5:5 + num_classes], 1, keepdim=True)\n",
        "\n",
        "        # 获得的内容为(x1, y1, x2, y2, obj_conf, class_conf, class_pred)\n",
        "        detections = torch.cat((image_pred[:, :5], class_conf.float(), class_pred.float()), 1)\n",
        "\n",
        "        # 获得种类\n",
        "        unique_labels = detections[:, -1].cpu().unique()\n",
        "\n",
        "        if prediction.is_cuda:\n",
        "            unique_labels = unique_labels.cuda()\n",
        "\n",
        "        for c in unique_labels:\n",
        "            # 获得某一类初步筛选后全部的预测结果\n",
        "            detections_class = detections[detections[:, -1] == c]\n",
        "            # 按照存在物体的置信度排序\n",
        "            _, conf_sort_index = torch.sort(detections_class[:, 4], descending=True)\n",
        "            detections_class = detections_class[conf_sort_index]\n",
        "            # 进行非极大抑制\n",
        "            max_detections = []\n",
        "            while detections_class.size(0):\n",
        "                # 取出这一类置信度最高的，一步一步往下判断，判断重合程度是否大于nms_thres，如果是则去除掉\n",
        "                max_detections.append(detections_class[0].unsqueeze(0))\n",
        "                if len(detections_class) == 1:\n",
        "                    break\n",
        "                ious = bbox_iou(max_detections[-1], detections_class[1:])\n",
        "                detections_class = detections_class[1:][ious < nms_thres]\n",
        "            # 堆叠\n",
        "            max_detections = torch.cat(max_detections).data\n",
        "            # Add max detections to outputs\n",
        "            output[image_i] = max_detections if output[image_i] is None else torch.cat(\n",
        "                (output[image_i], max_detections))\n",
        "\n",
        "    return output\n",
        "\n",
        "def merge_bboxes(bboxes, cutx, cuty):\n",
        "    merge_bbox = []\n",
        "    for i in range(len(bboxes)):\n",
        "        for box in bboxes[i]:\n",
        "            tmp_box = []\n",
        "            x1,y1,x2,y2 = box[0], box[1], box[2], box[3]\n",
        "\n",
        "            if i == 0:\n",
        "                if y1 > cuty or x1 > cutx:\n",
        "                    continue\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y2 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x2 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "                \n",
        "            if i == 1:\n",
        "                if y2 < cuty or x1 > cutx:\n",
        "                    continue\n",
        "\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y1 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "                \n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x2 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "\n",
        "            if i == 2:\n",
        "                if y2 < cuty or x2 < cutx:\n",
        "                    continue\n",
        "\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y1 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "\n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x1 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "\n",
        "            if i == 3:\n",
        "                if y1 > cuty or x2 < cutx:\n",
        "                    continue\n",
        "\n",
        "                if y2 >= cuty and y1 <= cuty:\n",
        "                    y2 = cuty\n",
        "                    if y2-y1 < 5:\n",
        "                        continue\n",
        "\n",
        "                if x2 >= cutx and x1 <= cutx:\n",
        "                    x1 = cutx\n",
        "                    if x2-x1 < 5:\n",
        "                        continue\n",
        "\n",
        "            tmp_box.append(x1)\n",
        "            tmp_box.append(y1)\n",
        "            tmp_box.append(x2)\n",
        "            tmp_box.append(y2)\n",
        "            tmp_box.append(box[-1])\n",
        "            merge_bbox.append(tmp_box)\n",
        "    return merge_bbox"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AZp4q7ODX5H7",
        "colab_type": "text"
      },
      "source": [
        "### nets.yolo_training"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSULB0IkX6NO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "  \n",
        "from random import shuffle\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import math\n",
        "import torch.nn.functional as F\n",
        "from matplotlib.colors import rgb_to_hsv, hsv_to_rgb\n",
        "from PIL import Image\n",
        "# from utils.utils import bbox_iou, merge_bboxes\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   平滑标签\n",
        "#---------------------------------------------------#\n",
        "def smooth_labels(y_true, label_smoothing,num_classes):\n",
        "    return y_true * (1.0 - label_smoothing) + label_smoothing / num_classes\n",
        "\n",
        "def box_ciou(b1, b2):\n",
        "    \"\"\"\n",
        "    输入为：\n",
        "    ----------\n",
        "    b1: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
        "    b2: tensor, shape=(batch, feat_w, feat_h, anchor_num, 4), xywh\n",
        "\n",
        "    返回为：\n",
        "    -------\n",
        "    ciou: tensor, shape=(batch, feat_w, feat_h, anchor_num, 1)\n",
        "    \"\"\"\n",
        "    # 求出预测框左上角右下角\n",
        "    b1_xy = b1[..., :2]\n",
        "    b1_wh = b1[..., 2:4]\n",
        "    b1_wh_half = b1_wh/2.\n",
        "    b1_mins = b1_xy - b1_wh_half\n",
        "    b1_maxes = b1_xy + b1_wh_half\n",
        "    # 求出真实框左上角右下角\n",
        "    b2_xy = b2[..., :2]\n",
        "    b2_wh = b2[..., 2:4]\n",
        "    b2_wh_half = b2_wh/2.\n",
        "    b2_mins = b2_xy - b2_wh_half\n",
        "    b2_maxes = b2_xy + b2_wh_half\n",
        "\n",
        "    # 求真实框和预测框所有的iou\n",
        "    intersect_mins = torch.max(b1_mins, b2_mins)\n",
        "    intersect_maxes = torch.min(b1_maxes, b2_maxes)\n",
        "    intersect_wh = torch.max(intersect_maxes - intersect_mins, torch.zeros_like(intersect_maxes))\n",
        "    intersect_area = intersect_wh[..., 0] * intersect_wh[..., 1]\n",
        "    b1_area = b1_wh[..., 0] * b1_wh[..., 1]\n",
        "    b2_area = b2_wh[..., 0] * b2_wh[..., 1]\n",
        "    union_area = b1_area + b2_area - intersect_area\n",
        "    iou = intersect_area / torch.clamp(union_area,min = 1e-6)\n",
        "\n",
        "    # 计算中心的差距\n",
        "    center_distance = torch.sum(torch.pow((b1_xy - b2_xy), 2), axis=-1)\n",
        "    \n",
        "    # 找到包裹两个框的最小框的左上角和右下角\n",
        "    enclose_mins = torch.min(b1_mins, b2_mins)\n",
        "    enclose_maxes = torch.max(b1_maxes, b2_maxes)\n",
        "    enclose_wh = torch.max(enclose_maxes - enclose_mins, torch.zeros_like(intersect_maxes))\n",
        "    # 计算对角线距离\n",
        "    enclose_diagonal = torch.sum(torch.pow(enclose_wh,2), axis=-1)\n",
        "    ciou = iou - 1.0 * (center_distance) / torch.clamp(enclose_diagonal,min = 1e-6)\n",
        "    \n",
        "    v = (4 / (math.pi ** 2)) * torch.pow((torch.atan(b1_wh[..., 0]/torch.clamp(b1_wh[..., 1],min = 1e-6)) - torch.atan(b2_wh[..., 0]/torch.clamp(b2_wh[..., 1],min = 1e-6))), 2)\n",
        "    alpha = v / torch.clamp((1.0 - iou + v),min=1e-6)\n",
        "    ciou = ciou - alpha * v\n",
        "    return ciou\n",
        "  \n",
        "def clip_by_tensor(t,t_min,t_max):\n",
        "    t=t.float()\n",
        "    result = (t >= t_min).float() * t + (t < t_min).float() * t_min\n",
        "    result = (result <= t_max).float() * result + (result > t_max).float() * t_max\n",
        "    return result\n",
        "\n",
        "def MSELoss(pred,target):\n",
        "    return (pred-target)**2\n",
        "\n",
        "def BCELoss(pred,target):\n",
        "    epsilon = 1e-7\n",
        "    pred = clip_by_tensor(pred, epsilon, 1.0 - epsilon)\n",
        "    output = -target * torch.log(pred) - (1.0 - target) * torch.log(1.0 - pred)\n",
        "    return output\n",
        "\n",
        "class YOLOLoss(nn.Module):\n",
        "    def __init__(self, anchors, num_classes, img_size, label_smooth=0, cuda=True):\n",
        "        super(YOLOLoss, self).__init__()\n",
        "        self.anchors = anchors\n",
        "        self.num_anchors = len(anchors)\n",
        "        self.num_classes = num_classes\n",
        "        self.bbox_attrs = 5 + num_classes\n",
        "        self.img_size = img_size\n",
        "        self.feature_length = [img_size[0]//32,img_size[0]//16,img_size[0]//8]\n",
        "        self.label_smooth = label_smooth\n",
        "\n",
        "        self.ignore_threshold = 0.5\n",
        "        self.lambda_conf = 1.0\n",
        "        self.lambda_cls = 1.0\n",
        "        self.lambda_loc = 1.0\n",
        "        self.cuda = cuda\n",
        "\n",
        "    def forward(self, input, targets=None):\n",
        "        # input为bs,3*(5+num_classes),13,13\n",
        "        \n",
        "        # 一共多少张图片\n",
        "        bs = input.size(0)\n",
        "        # 特征层的高\n",
        "        in_h = input.size(2)\n",
        "        # 特征层的宽\n",
        "        in_w = input.size(3)\n",
        "\n",
        "        # 计算步长\n",
        "        # 每一个特征点对应原来的图片上多少个像素点\n",
        "        # 如果特征层为13x13的话，一个特征点就对应原来的图片上的32个像素点\n",
        "        stride_h = self.img_size[1] / in_h\n",
        "        stride_w = self.img_size[0] / in_w\n",
        "\n",
        "        # 把先验框的尺寸调整成特征层大小的形式\n",
        "        # 计算出先验框在特征层上对应的宽高\n",
        "        scaled_anchors = [(a_w / stride_w, a_h / stride_h) for a_w, a_h in self.anchors]\n",
        "        # bs,3*(5+num_classes),13,13 -> bs,3,13,13,(5+num_classes)\n",
        "        prediction = input.view(bs, int(self.num_anchors/3),\n",
        "                                self.bbox_attrs, in_h, in_w).permute(0, 1, 3, 4, 2).contiguous()\n",
        "        \n",
        "        # 对prediction预测进行调整\n",
        "        conf = torch.sigmoid(prediction[..., 4])  # Conf\n",
        "        pred_cls = torch.sigmoid(prediction[..., 5:])  # Cls pred.\n",
        "\n",
        "        # 找到哪些先验框内部包含物体\n",
        "        mask, noobj_mask, t_box, tconf, tcls, box_loss_scale_x, box_loss_scale_y = self.get_target(targets, scaled_anchors,in_w, in_h,self.ignore_threshold)\n",
        "\n",
        "        noobj_mask, pred_boxes_for_ciou = self.get_ignore(prediction, targets, scaled_anchors, in_w, in_h, noobj_mask)\n",
        "\n",
        "        if self.cuda:\n",
        "            mask, noobj_mask = mask.cuda(), noobj_mask.cuda()\n",
        "            box_loss_scale_x, box_loss_scale_y= box_loss_scale_x.cuda(), box_loss_scale_y.cuda()\n",
        "            tconf, tcls = tconf.cuda(), tcls.cuda()\n",
        "            pred_boxes_for_ciou = pred_boxes_for_ciou.cuda()\n",
        "            t_box = t_box.cuda()\n",
        "\n",
        "        box_loss_scale = 2-box_loss_scale_x*box_loss_scale_y\n",
        "        #  losses.\n",
        "        ciou = (1 - box_ciou( pred_boxes_for_ciou[mask.bool()], t_box[mask.bool()]))* box_loss_scale[mask.bool()]\n",
        "\n",
        "        loss_loc = torch.sum(ciou / bs)\n",
        "        loss_conf = torch.sum(BCELoss(conf, mask) * mask / bs) + \\\n",
        "                    torch.sum(BCELoss(conf, mask) * noobj_mask / bs)\n",
        "                    \n",
        "        # print(smooth_labels(tcls[mask == 1],self.label_smooth,self.num_classes))\n",
        "        loss_cls = torch.sum(BCELoss(pred_cls[mask == 1], smooth_labels(tcls[mask == 1],self.label_smooth,self.num_classes))/bs)\n",
        "        # print(loss_loc,loss_conf,loss_cls)\n",
        "        loss = loss_conf * self.lambda_conf + loss_cls * self.lambda_cls + loss_loc * self.lambda_loc\n",
        "        return loss, loss_conf.item(), loss_cls.item(), loss_loc.item()\n",
        "\n",
        "    def get_target(self, target, anchors, in_w, in_h, ignore_threshold):\n",
        "        # 计算一共有多少张图片\n",
        "        bs = len(target)\n",
        "        # 获得先验框\n",
        "        anchor_index = [[0,1,2],[3,4,5],[6,7,8]][self.feature_length.index(in_w)]\n",
        "        subtract_index = [0,3,6][self.feature_length.index(in_w)]\n",
        "        # 创建全是0或者全是1的阵列\n",
        "        mask = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        noobj_mask = torch.ones(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "\n",
        "        tx = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        ty = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        tw = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        th = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        t_box = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, 4, requires_grad=False)\n",
        "        tconf = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        tcls = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, self.num_classes, requires_grad=False)\n",
        "\n",
        "        box_loss_scale_x = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        box_loss_scale_y = torch.zeros(bs, int(self.num_anchors/3), in_h, in_w, requires_grad=False)\n",
        "        for b in range(bs):\n",
        "            for t in range(target[b].shape[0]):\n",
        "                # 计算出在特征层上的点位\n",
        "                gx = target[b][t, 0] * in_w\n",
        "                gy = target[b][t, 1] * in_h\n",
        "                \n",
        "                gw = target[b][t, 2] * in_w\n",
        "                gh = target[b][t, 3] * in_h\n",
        "\n",
        "                # 计算出属于哪个网格\n",
        "                gi = int(gx)\n",
        "                gj = int(gy)\n",
        "\n",
        "                # 计算真实框的位置\n",
        "                gt_box = torch.FloatTensor(np.array([0, 0, gw, gh])).unsqueeze(0)\n",
        "                \n",
        "                # 计算出所有先验框的位置\n",
        "                anchor_shapes = torch.FloatTensor(np.concatenate((np.zeros((self.num_anchors, 2)),\n",
        "                                                                  np.array(anchors)), 1))\n",
        "                # 计算重合程度\n",
        "                anch_ious = bbox_iou(gt_box, anchor_shapes)\n",
        "               \n",
        "                # Find the best matching anchor box\n",
        "                best_n = np.argmax(anch_ious)\n",
        "                if best_n not in anchor_index:\n",
        "                    continue\n",
        "                # Masks\n",
        "                if (gj < in_h) and (gi < in_w):\n",
        "                    best_n = best_n - subtract_index\n",
        "                    # 判定哪些先验框内部真实的存在物体\n",
        "                    noobj_mask[b, best_n, gj, gi] = 0\n",
        "                    mask[b, best_n, gj, gi] = 1\n",
        "                    # 计算先验框中心调整参数\n",
        "                    tx[b, best_n, gj, gi] = gx\n",
        "                    ty[b, best_n, gj, gi] = gy\n",
        "                    # 计算先验框宽高调整参数\n",
        "                    tw[b, best_n, gj, gi] = gw\n",
        "                    th[b, best_n, gj, gi] = gh\n",
        "                    # 用于获得xywh的比例\n",
        "                    box_loss_scale_x[b, best_n, gj, gi] = target[b][t, 2]\n",
        "                    box_loss_scale_y[b, best_n, gj, gi] = target[b][t, 3]\n",
        "                    # 物体置信度\n",
        "                    tconf[b, best_n, gj, gi] = 1\n",
        "                    # 种类\n",
        "                    tcls[b, best_n, gj, gi, int(target[b][t, 4])] = 1\n",
        "                else:\n",
        "                    print('Step {0} out of bound'.format(b))\n",
        "                    print('gj: {0}, height: {1} | gi: {2}, width: {3}'.format(gj, in_h, gi, in_w))\n",
        "                    continue\n",
        "        t_box[...,0] = tx\n",
        "        t_box[...,1] = ty\n",
        "        t_box[...,2] = tw\n",
        "        t_box[...,3] = th\n",
        "        return mask, noobj_mask, t_box, tconf, tcls, box_loss_scale_x, box_loss_scale_y\n",
        "\n",
        "    def get_ignore(self,prediction,target,scaled_anchors,in_w, in_h,noobj_mask):\n",
        "        bs = len(target)\n",
        "        anchor_index = [[0,1,2],[3,4,5],[6,7,8]][self.feature_length.index(in_w)]\n",
        "        scaled_anchors = np.array(scaled_anchors)[anchor_index]\n",
        "        # 先验框的中心位置的调整参数\n",
        "        x = torch.sigmoid(prediction[..., 0])  \n",
        "        y = torch.sigmoid(prediction[..., 1])\n",
        "        # 先验框的宽高调整参数\n",
        "        w = prediction[..., 2]  # Width\n",
        "        h = prediction[..., 3]  # Height\n",
        "\n",
        "        FloatTensor = torch.cuda.FloatTensor if x.is_cuda else torch.FloatTensor\n",
        "        LongTensor = torch.cuda.LongTensor if x.is_cuda else torch.LongTensor\n",
        "\n",
        "        # 生成网格，先验框中心，网格左上角\n",
        "        grid_x = torch.linspace(0, in_w - 1, in_w).repeat(in_w, 1).repeat(\n",
        "            int(bs*self.num_anchors/3), 1, 1).view(x.shape).type(FloatTensor)\n",
        "        grid_y = torch.linspace(0, in_h - 1, in_h).repeat(in_h, 1).t().repeat(\n",
        "            int(bs*self.num_anchors/3), 1, 1).view(y.shape).type(FloatTensor)\n",
        "\n",
        "        # 生成先验框的宽高\n",
        "        anchor_w = FloatTensor(scaled_anchors).index_select(1, LongTensor([0]))\n",
        "        anchor_h = FloatTensor(scaled_anchors).index_select(1, LongTensor([1]))\n",
        "        \n",
        "        anchor_w = anchor_w.repeat(bs, 1).repeat(1, 1, in_h * in_w).view(w.shape)\n",
        "        anchor_h = anchor_h.repeat(bs, 1).repeat(1, 1, in_h * in_w).view(h.shape)\n",
        "        \n",
        "        # 计算调整后的先验框中心与宽高\n",
        "        pred_boxes = FloatTensor(prediction[..., :4].shape)\n",
        "        pred_boxes[..., 0] = x + grid_x\n",
        "        pred_boxes[..., 1] = y + grid_y\n",
        "        pred_boxes[..., 2] = torch.exp(w) * anchor_w\n",
        "        pred_boxes[..., 3] = torch.exp(h) * anchor_h\n",
        "        for i in range(bs):\n",
        "            pred_boxes_for_ignore = pred_boxes[i]\n",
        "            pred_boxes_for_ignore = pred_boxes_for_ignore.view(-1, 4)\n",
        "\n",
        "            for t in range(target[i].shape[0]):\n",
        "                gx = target[i][t, 0] * in_w\n",
        "                gy = target[i][t, 1] * in_h\n",
        "                gw = target[i][t, 2] * in_w\n",
        "                gh = target[i][t, 3] * in_h\n",
        "                gt_box = torch.FloatTensor(np.array([gx, gy, gw, gh])).unsqueeze(0).type(FloatTensor)\n",
        "\n",
        "                anch_ious = bbox_iou(gt_box, pred_boxes_for_ignore, x1y1x2y2=False)\n",
        "                anch_ious = anch_ious.view(pred_boxes[i].size()[:3])\n",
        "                noobj_mask[i][anch_ious>self.ignore_threshold] = 0\n",
        "        return noobj_mask, pred_boxes\n",
        "\n",
        "\n",
        "def rand(a=0, b=1):\n",
        "    return np.random.rand()*(b-a) + a\n",
        "\n",
        "\n",
        "class Generator(object):\n",
        "    def __init__(self,batch_size,\n",
        "                 train_lines, image_size,\n",
        "                 ):\n",
        "        \n",
        "        self.batch_size = batch_size\n",
        "        self.train_lines = train_lines\n",
        "        self.train_batches = len(train_lines)\n",
        "        self.image_size = image_size\n",
        "        \n",
        "    def get_random_data(self, annotation_line, input_shape, jitter=.3, hue=.1, sat=1.5, val=1.5):\n",
        "        '''r实时数据增强的随机预处理'''\n",
        "        line = annotation_line.split()\n",
        "        line[0] = line[0] + ' ' + line[1]\n",
        "        del line[1]\n",
        "        # print(line)\n",
        "        image = Image.open(line[0])\n",
        "        iw, ih = image.size\n",
        "        h, w = input_shape\n",
        "        box = np.array([np.array(list(map(int,box.split(',')))) for box in line[1:]])\n",
        "\n",
        "        # resize image\n",
        "        new_ar = w/h * rand(1-jitter,1+jitter)/rand(1-jitter,1+jitter)\n",
        "        scale = rand(.25, 2)\n",
        "        if new_ar < 1:\n",
        "            nh = int(scale*h)\n",
        "            nw = int(nh*new_ar)\n",
        "        else:\n",
        "            nw = int(scale*w)\n",
        "            nh = int(nw/new_ar)\n",
        "        image = image.resize((nw,nh), Image.BICUBIC)\n",
        "\n",
        "        # place image\n",
        "        dx = int(rand(0, w-nw))\n",
        "        dy = int(rand(0, h-nh))\n",
        "        new_image = Image.new('RGB', (w,h), (128,128,128))\n",
        "        new_image.paste(image, (dx, dy))\n",
        "        image = new_image\n",
        "\n",
        "        # flip image or not\n",
        "        flip = rand()<.5\n",
        "        if flip: image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "\n",
        "        # distort image\n",
        "        hue = rand(-hue, hue)\n",
        "        sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
        "        val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
        "        x = rgb_to_hsv(np.array(image)/255.)\n",
        "        x[..., 0] += hue\n",
        "        x[..., 0][x[..., 0]>1] -= 1\n",
        "        x[..., 0][x[..., 0]<0] += 1\n",
        "        x[..., 1] *= sat\n",
        "        x[..., 2] *= val\n",
        "        x[x>1] = 1\n",
        "        x[x<0] = 0\n",
        "        image_data = hsv_to_rgb(x)*255 # numpy array, 0 to 1\n",
        "\n",
        "        # correct boxes\n",
        "        box_data = np.zeros((len(box),5))\n",
        "        if len(box)>0:\n",
        "            np.random.shuffle(box)\n",
        "            box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
        "            box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
        "            if flip: box[:, [0,2]] = w - box[:, [2,0]]\n",
        "            box[:, 0:2][box[:, 0:2]<0] = 0\n",
        "            box[:, 2][box[:, 2]>w] = w\n",
        "            box[:, 3][box[:, 3]>h] = h\n",
        "            box_w = box[:, 2] - box[:, 0]\n",
        "            box_h = box[:, 3] - box[:, 1]\n",
        "            box = box[np.logical_and(box_w>1, box_h>1)] # discard invalid box\n",
        "            box_data = np.zeros((len(box),5))\n",
        "            box_data[:len(box)] = box\n",
        "        if len(box) == 0:\n",
        "            return image_data, []\n",
        "\n",
        "        if (box_data[:,:4]>0).any():\n",
        "            return image_data, box_data\n",
        "        else:\n",
        "            return image_data, []\n",
        "\n",
        "    def get_random_data_with_Mosaic(self, annotation_line, input_shape, hue=.1, sat=1.5, val=1.5):\n",
        "        '''random preprocessing for real-time data augmentation'''\n",
        "        h, w = input_shape\n",
        "        min_offset_x = 0.4\n",
        "        min_offset_y = 0.4\n",
        "        scale_low = 1-min(min_offset_x,min_offset_y)\n",
        "        scale_high = scale_low+0.2\n",
        "\n",
        "        image_datas = [] \n",
        "        box_datas = []\n",
        "        index = 0\n",
        "\n",
        "        place_x = [0,0,int(w*min_offset_x),int(w*min_offset_x)]\n",
        "        place_y = [0,int(h*min_offset_y),int(w*min_offset_y),0]\n",
        "        for line in annotation_line:\n",
        "            # 每一行进行分割\n",
        "            line_content = line.split()\n",
        "            line_content[0] = line_content[0] + ' ' + line_content[1]\n",
        "            del line_content[1]\n",
        "            # 打开图片\n",
        "            image = Image.open(line_content[0])\n",
        "            image = image.convert(\"RGB\") \n",
        "            # 图片的大小\n",
        "            iw, ih = image.size\n",
        "            # 保存框的位置\n",
        "            box = np.array([np.array(list(map(int,box.split(',')))) for box in line_content[1:]])\n",
        "            \n",
        "            # 是否翻转图片\n",
        "            flip = rand()<.5\n",
        "            if flip and len(box)>0:\n",
        "                image = image.transpose(Image.FLIP_LEFT_RIGHT)\n",
        "                box[:, [0,2]] = iw - box[:, [2,0]]\n",
        "\n",
        "            # 对输入进来的图片进行缩放\n",
        "            new_ar = w/h\n",
        "            scale = rand(scale_low, scale_high)\n",
        "            if new_ar < 1:\n",
        "                nh = int(scale*h)\n",
        "                nw = int(nh*new_ar)\n",
        "            else:\n",
        "                nw = int(scale*w)\n",
        "                nh = int(nw/new_ar)\n",
        "            image = image.resize((nw,nh), Image.BICUBIC)\n",
        "\n",
        "            # 进行色域变换\n",
        "            hue = rand(-hue, hue)\n",
        "            sat = rand(1, sat) if rand()<.5 else 1/rand(1, sat)\n",
        "            val = rand(1, val) if rand()<.5 else 1/rand(1, val)\n",
        "            x = rgb_to_hsv(np.array(image)/255.)\n",
        "            x[..., 0] += hue\n",
        "            x[..., 0][x[..., 0]>1] -= 1\n",
        "            x[..., 0][x[..., 0]<0] += 1\n",
        "            x[..., 1] *= sat\n",
        "            x[..., 2] *= val\n",
        "            x[x>1] = 1\n",
        "            x[x<0] = 0\n",
        "            image = hsv_to_rgb(x)\n",
        "\n",
        "            image = Image.fromarray((image*255).astype(np.uint8))\n",
        "            # 将图片进行放置，分别对应四张分割图片的位置\n",
        "            dx = place_x[index]\n",
        "            dy = place_y[index]\n",
        "            new_image = Image.new('RGB', (w,h), (128,128,128))\n",
        "            new_image.paste(image, (dx, dy))\n",
        "            image_data = np.array(new_image)\n",
        "\n",
        "            \n",
        "            index = index + 1\n",
        "            box_data = []\n",
        "            # 对box进行重新处理\n",
        "            if len(box)>0:\n",
        "                np.random.shuffle(box)\n",
        "                box[:, [0,2]] = box[:, [0,2]]*nw/iw + dx\n",
        "                box[:, [1,3]] = box[:, [1,3]]*nh/ih + dy\n",
        "                box[:, 0:2][box[:, 0:2]<0] = 0\n",
        "                box[:, 2][box[:, 2]>w] = w\n",
        "                box[:, 3][box[:, 3]>h] = h\n",
        "                box_w = box[:, 2] - box[:, 0]\n",
        "                box_h = box[:, 3] - box[:, 1]\n",
        "                box = box[np.logical_and(box_w>1, box_h>1)]\n",
        "                box_data = np.zeros((len(box),5))\n",
        "                box_data[:len(box)] = box\n",
        "            \n",
        "            image_datas.append(image_data)\n",
        "            box_datas.append(box_data)\n",
        "\n",
        "        # 将图片分割，放在一起\n",
        "        cutx = np.random.randint(int(w*min_offset_x), int(w*(1 - min_offset_x)))\n",
        "        cuty = np.random.randint(int(h*min_offset_y), int(h*(1 - min_offset_y)))\n",
        "\n",
        "        new_image = np.zeros([h,w,3])\n",
        "        new_image[:cuty, :cutx, :] = image_datas[0][:cuty, :cutx, :]\n",
        "        new_image[cuty:, :cutx, :] = image_datas[1][cuty:, :cutx, :]\n",
        "        new_image[cuty:, cutx:, :] = image_datas[2][cuty:, cutx:, :]\n",
        "        new_image[:cuty, cutx:, :] = image_datas[3][:cuty, cutx:, :]\n",
        "\n",
        "        # 对框进行进一步的处理\n",
        "        new_boxes = np.array(merge_bboxes(box_datas, cutx, cuty))\n",
        "\n",
        "        if len(new_boxes) == 0:\n",
        "            return new_image, []\n",
        "        if (new_boxes[:,:4]>0).any():\n",
        "            return new_image, new_boxes\n",
        "        else:\n",
        "            return new_image, []\n",
        "\n",
        "    def generate(self, train = True, mosaic = True):\n",
        "        while True:\n",
        "            shuffle(self.train_lines)\n",
        "            lines = self.train_lines\n",
        "            inputs = []\n",
        "            targets = []\n",
        "            flag = True\n",
        "            n = len(lines)\n",
        "            for i in range(len(lines)):\n",
        "                if mosaic == True:\n",
        "                    if flag and (i+4) < n:\n",
        "                        img,y = self.get_random_data_with_Mosaic(lines[i:i+4], self.image_size[0:2])\n",
        "                        i = (i+4) % n\n",
        "                    else:\n",
        "                        img,y = self.get_random_data(lines[i], self.image_size[0:2])\n",
        "                        i = (i+1) % n\n",
        "                    flag = bool(1-flag)\n",
        "                else:\n",
        "                    img,y = self.get_random_data(lines[i], self.image_size[0:2])\n",
        "                    i = (i+1) % n\n",
        "                if len(y)==0:\n",
        "                    continue\n",
        "                boxes = np.array(y[:,:4],dtype=np.float32)\n",
        "                boxes[:,0] = boxes[:,0]/self.image_size[1]\n",
        "                boxes[:,1] = boxes[:,1]/self.image_size[0]\n",
        "                boxes[:,2] = boxes[:,2]/self.image_size[1]\n",
        "                boxes[:,3] = boxes[:,3]/self.image_size[0]\n",
        "\n",
        "                boxes = np.maximum(np.minimum(boxes,1),0)\n",
        "                boxes[:,2] = boxes[:,2] - boxes[:,0]\n",
        "                boxes[:,3] = boxes[:,3] - boxes[:,1]\n",
        "  \n",
        "                boxes[:,0] = boxes[:,0] + boxes[:,2]/2\n",
        "                boxes[:,1] = boxes[:,1] + boxes[:,3]/2\n",
        "                y = np.concatenate([boxes,y[:,-1:]],axis=-1)\n",
        "                img = np.array(img,dtype = np.float32)\n",
        "\n",
        "                inputs.append(np.transpose(img/255.0,(2,0,1)))                \n",
        "                targets.append(y)\n",
        "                if len(targets) == self.batch_size:\n",
        "                    tmp_inp = np.array(inputs)\n",
        "                    tmp_targets = np.array(targets)\n",
        "                    inputs = []\n",
        "                    targets = []\n",
        "                    yield tmp_inp, tmp_targets\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "a3LR1kbRWfLr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import os\n",
        "import time\n",
        "import copy\n",
        "import torch\n",
        "import numpy as np\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "import torch.backends.cudnn as cudnn\n",
        "# from nets.yolo4 import YoloBody\n",
        "# from nets.yolo_training import YOLOLoss, Generator"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GURw3fNiWfLv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#---------------------------------------------------#\n",
        "#   获得类和先验框\n",
        "#---------------------------------------------------#\n",
        "def get_classes(classes_path):\n",
        "    '''loads the classes'''\n",
        "    with open(classes_path) as f:\n",
        "        class_names = f.readlines()\n",
        "    class_names = [c.strip() for c in class_names]\n",
        "    return class_names\n",
        "\n",
        "\n",
        "def get_anchors(anchors_path):\n",
        "    '''loads the anchors from a file'''\n",
        "    with open(anchors_path) as f:\n",
        "        anchors = f.readline()\n",
        "    anchors = [float(x) for x in anchors.split(',')]\n",
        "    return np.array(anchors).reshape([-1,3,2])[::-1,:,:]\n",
        "\n",
        "\n",
        "#---------------------------------------------------#\n",
        "#   训练一个epoch\n",
        "#---------------------------------------------------#\n",
        "def fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen,genval, Epoch, cuda, optimizer, lr_scheduler):\n",
        "    total_loss = 0\n",
        "    val_loss = 0\n",
        "    print('\\n' + '-' * 10 + 'Train one epoch.' + '-' * 10)\n",
        "    print('Epoch:'+ str(epoch+1) + '/' + str(Epoch))\n",
        "    print('Start Training.')\n",
        "    net.train()\n",
        "    for iteration in range(epoch_size):\n",
        "        start_time = time.time()\n",
        "        images, targets = next(gen)\n",
        "        with torch.no_grad():\n",
        "            if cuda:\n",
        "                images = Variable(torch.from_numpy(images).type(torch.FloatTensor)).cuda()\n",
        "                targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
        "            else:\n",
        "                images = Variable(torch.from_numpy(images).type(torch.FloatTensor))\n",
        "                targets = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets]\n",
        "        optimizer.zero_grad()\n",
        "        outputs = net(images)\n",
        "        losses = []\n",
        "        for i in range(3):\n",
        "            loss_item = yolo_losses[i](outputs[i], targets)\n",
        "            losses.append(loss_item[0])\n",
        "        loss = sum(losses)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        lr_scheduler.step()\n",
        "\n",
        "        total_loss += loss\n",
        "        waste_time = time.time() - start_time\n",
        "        if iteration == 0 or (iteration+1) % 10 == 0:\n",
        "            print('step:' + str(iteration+1) + '/' + str(epoch_size) + ' || Total Loss: %.4f || %.4fs/step' % (total_loss/(iteration+1), waste_time))\n",
        "    print('Finish Training.')\n",
        "    '''        \n",
        "    print('Start Validation.')\n",
        "    net.eval()\n",
        "    for iteration in range(epoch_size_val):\n",
        "        images_val, targets_val = next(genval)\n",
        "\n",
        "        with torch.no_grad():\n",
        "            if cuda:\n",
        "                images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor)).cuda()\n",
        "                targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
        "            else:\n",
        "                images_val = Variable(torch.from_numpy(images_val).type(torch.FloatTensor))\n",
        "                targets_val = [Variable(torch.from_numpy(ann).type(torch.FloatTensor)) for ann in targets_val]\n",
        "            optimizer.zero_grad()\n",
        "            outputs = net(images_val)\n",
        "            losses = []\n",
        "            for i in range(3):\n",
        "                loss_item = yolo_losses[i](outputs[i], targets_val)\n",
        "                losses.append(loss_item[0])\n",
        "            loss = sum(losses)\n",
        "            val_loss += loss\n",
        "    print('Finish Validation')\n",
        "    '''\n",
        "    print('Total Loss: %.4f || Val Loss: %.4f ' % (total_loss/(epoch_size+1), val_loss/(epoch_size_val+1)))\n",
        "    \n",
        "    return total_loss/(epoch_size+1), val_loss/(epoch_size_val+1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dxz15R--WfLx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "#-------------------------------#\n",
        "#   输入的shape大小\n",
        "#   显存比较小可以使用416x416\n",
        "#   显存比较大可以使用608x608\n",
        "#-------------------------------#\n",
        "#input_shape = (416,416)\n",
        "input_shape = (608, 608)\n",
        "\n",
        "#-------------------------------#\n",
        "#   tricks的使用设置\n",
        "#-------------------------------#\n",
        "Cosine_lr = True\n",
        "mosaic = True\n",
        "# 用于设定是否使用cuda\n",
        "Cuda = True\n",
        "smoooth_label = 0.03\n",
        "\n",
        "#-------------------------------#\n",
        "#   获得训练集和验证集的annotations\n",
        "#   \n",
        "#-------------------------------#\n",
        "train_annotation_path = '/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/mask_train0.txt'\n",
        "val_annotation_path = '/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/mask_val.txt'\n",
        "\n",
        "#-------------------------------#\n",
        "#   获得先验框和类\n",
        "#-------------------------------#\n",
        "anchors_path = '/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/yolo_anchors.txt'\n",
        "classes_path = '/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/mask_classes.txt'   \n",
        "class_names = get_classes(classes_path)\n",
        "anchors = get_anchors(anchors_path)\n",
        "num_classes = len(class_names)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9SCHYBk7WfL0",
        "colab_type": "code",
        "outputId": "e0fb878a-45de-4656-ae12-cb20060b94d8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "# 创建模型\n",
        "model = YoloBody(len(anchors[0]), num_classes)\n",
        "#model_path = \"model_data/yolov4_coco_pretrained_weights.pth\"\n",
        "model_path = \"/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/yolov4_coco_pretrained_weights.pth\"\n",
        "# 加快模型训练的效率\n",
        "print('Loading pretrained model weights.')\n",
        "model_dict = model.state_dict()\n",
        "pretrained_dict = torch.load(model_path)\n",
        "pretrained_dict = {k: v for k, v in pretrained_dict.items() if np.shape(model_dict[k]) ==  np.shape(v)}\n",
        "model_dict.update(pretrained_dict)\n",
        "model.load_state_dict(model_dict)\n",
        "print('Finished!')\n",
        "\n",
        "if Cuda:\n",
        "    net = torch.nn.DataParallel(model)\n",
        "    cudnn.benchmark = True\n",
        "    net = net.cuda()\n",
        "\n",
        "# 建立loss函数\n",
        "yolo_losses = []\n",
        "for i in range(3):\n",
        "    yolo_losses.append(YOLOLoss(np.reshape(anchors, [-1,2]), num_classes, \\\n",
        "                                (input_shape[1], input_shape[0]), smoooth_label, Cuda))\n",
        "# read train lines and val lines\n",
        "with open(train_annotation_path) as f:\n",
        "    train_lines = f.readlines()\n",
        "with open(val_annotation_path) as f:\n",
        "    val_lines = f.readlines()\n",
        "num_train = len(train_lines)\n",
        "num_val = len(val_lines)"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loading pretrained model weights.\n",
            "Finished!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vSyV6g91WfL2",
        "colab_type": "code",
        "outputId": "ae340e00-64e0-4d7e-a482-9e5cbc39cdf8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#------------------------------------#\n",
        "#   先冻结backbone训练\n",
        "#------------------------------------#\n",
        "lr = 1e-3\n",
        "Batch_size = 4\n",
        "Init_Epoch = 0\n",
        "Freeze_Epoch = 25\n",
        "        \n",
        "optimizer = optim.Adam(net.parameters(), lr, weight_decay=5e-4)\n",
        "if Cosine_lr:\n",
        "    lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
        "else:\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "gen = Generator(Batch_size, train_lines, (input_shape[0], input_shape[1])).generate(mosaic = mosaic)\n",
        "gen_val = Generator(Batch_size, val_lines, (input_shape[0], input_shape[1])).generate(mosaic = False)\n",
        "                        \n",
        "epoch_size = int(max(1, num_train//Batch_size//2.5)) if mosaic else max(1, num_train//Batch_size)\n",
        "epoch_size_val = num_val//Batch_size\n",
        "for param in model.backbone.parameters():\n",
        "    param.requires_grad = False\n",
        "\n",
        "best_loss = 99999999.0\n",
        "best_model_weights = copy.deepcopy(net.state_dict())\n",
        "for epoch in range(Init_Epoch, Freeze_Epoch):\n",
        "    total_loss, val_loss = fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, gen_val, \n",
        "                                         Freeze_Epoch, Cuda, optimizer, lr_scheduler)\n",
        "    if total_loss < best_loss:\n",
        "        best_loss = total_loss\n",
        "        best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    with open('/content/gdrive/My Drive/cv_final/yolo_pytorch/total_loss.csv', mode='a+') as total_loss_file:\n",
        "        total_loss_file.write(str(total_loss.item()) + '\\n')\n",
        "    #with open('val_loss.csv', mode='a+') as val_loss_file:\n",
        "    #    val_loss_file.write(str(val_loss.item()) + '\\n')\n",
        "torch.save(best_model_weights, '/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/yolov4_maskdetect_weights0.pth')"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:1/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 17490.5039 || 14.2132s/step\n",
            "step:10/156 || Total Loss: 13773.3818 || 3.3775s/step\n",
            "step:20/156 || Total Loss: 11127.4785 || 3.7848s/step\n",
            "step:30/156 || Total Loss: 9193.3994 || 2.9623s/step\n",
            "step:40/156 || Total Loss: 7715.2915 || 3.3189s/step\n",
            "step:50/156 || Total Loss: 6602.6616 || 4.9550s/step\n",
            "step:60/156 || Total Loss: 5758.5557 || 3.0404s/step\n",
            "step:70/156 || Total Loss: 5102.8022 || 3.2862s/step\n",
            "step:80/156 || Total Loss: 4577.3687 || 3.2757s/step\n",
            "step:90/156 || Total Loss: 4151.0464 || 2.9407s/step\n",
            "step:100/156 || Total Loss: 3796.8745 || 3.4878s/step\n",
            "step:110/156 || Total Loss: 3501.4001 || 3.5916s/step\n",
            "step:120/156 || Total Loss: 3248.8115 || 3.5557s/step\n",
            "step:130/156 || Total Loss: 3031.6333 || 3.4672s/step\n",
            "step:140/156 || Total Loss: 2841.4473 || 3.5018s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step:150/156 || Total Loss: 2675.2312 || 4.4566s/step\n",
            "Finish Training.\n",
            "Total Loss: 2568.5642 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:2/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 295.1785 || 3.2483s/step\n",
            "step:10/156 || Total Loss: 284.5654 || 3.1666s/step\n",
            "step:20/156 || Total Loss: 286.0981 || 3.8443s/step\n",
            "step:30/156 || Total Loss: 272.4633 || 3.7093s/step\n",
            "step:40/156 || Total Loss: 262.2405 || 3.8395s/step\n",
            "step:50/156 || Total Loss: 253.5134 || 3.7023s/step\n",
            "step:60/156 || Total Loss: 246.1536 || 3.2786s/step\n",
            "step:70/156 || Total Loss: 238.7160 || 3.5832s/step\n",
            "step:80/156 || Total Loss: 232.9417 || 3.8741s/step\n",
            "step:90/156 || Total Loss: 225.7561 || 3.2018s/step\n",
            "step:100/156 || Total Loss: 218.0528 || 3.5607s/step\n",
            "step:110/156 || Total Loss: 211.4056 || 2.8524s/step\n",
            "step:120/156 || Total Loss: 204.6984 || 3.0518s/step\n",
            "step:130/156 || Total Loss: 200.4939 || 3.1855s/step\n",
            "step:140/156 || Total Loss: 199.7991 || 2.8038s/step\n",
            "step:150/156 || Total Loss: 196.1469 || 3.5692s/step\n",
            "Finish Training.\n",
            "Total Loss: 192.0042 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:3/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 115.3729 || 3.3470s/step\n",
            "step:10/156 || Total Loss: 123.5303 || 3.1822s/step\n",
            "step:20/156 || Total Loss: 118.3281 || 4.0217s/step\n",
            "step:30/156 || Total Loss: 114.4456 || 3.6758s/step\n",
            "step:40/156 || Total Loss: 115.4763 || 3.4071s/step\n",
            "step:50/156 || Total Loss: 111.8503 || 4.2112s/step\n",
            "step:60/156 || Total Loss: 109.4972 || 3.4047s/step\n",
            "step:70/156 || Total Loss: 110.7068 || 3.3464s/step\n",
            "step:80/156 || Total Loss: 108.2460 || 1.5692s/step\n",
            "step:90/156 || Total Loss: 106.9069 || 1.5825s/step\n",
            "step:100/156 || Total Loss: 105.7165 || 1.3723s/step\n",
            "step:110/156 || Total Loss: 104.1860 || 1.4603s/step\n",
            "step:120/156 || Total Loss: 104.3606 || 1.8649s/step\n",
            "step:130/156 || Total Loss: 102.5618 || 1.4544s/step\n",
            "step:140/156 || Total Loss: 101.5003 || 1.5016s/step\n",
            "step:150/156 || Total Loss: 100.9358 || 1.6195s/step\n",
            "Finish Training.\n",
            "Total Loss: 99.0449 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:4/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 138.1943 || 1.5623s/step\n",
            "step:10/156 || Total Loss: 74.8412 || 1.4240s/step\n",
            "step:20/156 || Total Loss: 78.7704 || 1.6955s/step\n",
            "step:30/156 || Total Loss: 77.6195 || 1.2850s/step\n",
            "step:40/156 || Total Loss: 73.6772 || 1.6553s/step\n",
            "step:50/156 || Total Loss: 71.5317 || 1.3842s/step\n",
            "step:60/156 || Total Loss: 71.1776 || 1.3938s/step\n",
            "step:70/156 || Total Loss: 73.0541 || 1.4615s/step\n",
            "step:80/156 || Total Loss: 71.3622 || 1.6502s/step\n",
            "step:90/156 || Total Loss: 70.0532 || 1.6124s/step\n",
            "step:100/156 || Total Loss: 70.3036 || 1.4785s/step\n",
            "step:110/156 || Total Loss: 71.8646 || 1.2726s/step\n",
            "step:120/156 || Total Loss: 71.1023 || 1.5471s/step\n",
            "step:130/156 || Total Loss: 71.1292 || 2.0566s/step\n",
            "step:140/156 || Total Loss: 70.1745 || 1.4335s/step\n",
            "step:150/156 || Total Loss: 72.1731 || 1.3555s/step\n",
            "Finish Training.\n",
            "Total Loss: 71.4407 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:5/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 55.9996 || 1.5855s/step\n",
            "step:10/156 || Total Loss: 73.9090 || 1.7037s/step\n",
            "step:20/156 || Total Loss: 66.7620 || 2.3560s/step\n",
            "step:30/156 || Total Loss: 60.7580 || 1.5375s/step\n",
            "step:40/156 || Total Loss: 61.4290 || 1.6159s/step\n",
            "step:50/156 || Total Loss: 62.4110 || 1.6032s/step\n",
            "step:60/156 || Total Loss: 61.3262 || 1.5413s/step\n",
            "step:70/156 || Total Loss: 59.7896 || 1.4891s/step\n",
            "step:80/156 || Total Loss: 58.3973 || 1.6809s/step\n",
            "step:90/156 || Total Loss: 58.8476 || 1.4675s/step\n",
            "step:100/156 || Total Loss: 57.8354 || 1.3958s/step\n",
            "step:110/156 || Total Loss: 56.9150 || 1.5667s/step\n",
            "step:120/156 || Total Loss: 55.6577 || 1.4127s/step\n",
            "step:130/156 || Total Loss: 55.5319 || 1.7452s/step\n",
            "step:140/156 || Total Loss: 56.5715 || 1.6213s/step\n",
            "step:150/156 || Total Loss: 56.2313 || 1.7385s/step\n",
            "Finish Training.\n",
            "Total Loss: 55.3631 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:6/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 52.9945 || 1.6913s/step\n",
            "step:10/156 || Total Loss: 38.9669 || 1.7815s/step\n",
            "step:20/156 || Total Loss: 43.4977 || 1.8019s/step\n",
            "step:30/156 || Total Loss: 46.0903 || 1.6237s/step\n",
            "step:40/156 || Total Loss: 48.3472 || 1.4979s/step\n",
            "step:50/156 || Total Loss: 46.3974 || 1.6055s/step\n",
            "step:60/156 || Total Loss: 46.1212 || 1.5203s/step\n",
            "step:70/156 || Total Loss: 45.0673 || 1.5074s/step\n",
            "step:80/156 || Total Loss: 45.5321 || 1.5956s/step\n",
            "step:90/156 || Total Loss: 46.5785 || 1.6460s/step\n",
            "step:100/156 || Total Loss: 46.1520 || 1.3459s/step\n",
            "step:110/156 || Total Loss: 45.4323 || 1.6845s/step\n",
            "step:120/156 || Total Loss: 44.8474 || 1.4007s/step\n",
            "step:130/156 || Total Loss: 44.1323 || 1.5266s/step\n",
            "step:140/156 || Total Loss: 44.3467 || 1.4624s/step\n",
            "step:150/156 || Total Loss: 44.3150 || 1.4145s/step\n",
            "Finish Training.\n",
            "Total Loss: 44.1167 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:7/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 41.3658 || 1.4705s/step\n",
            "step:10/156 || Total Loss: 45.2007 || 1.3826s/step\n",
            "step:20/156 || Total Loss: 40.8989 || 1.6464s/step\n",
            "step:30/156 || Total Loss: 38.3543 || 1.5483s/step\n",
            "step:40/156 || Total Loss: 38.6105 || 1.4799s/step\n",
            "step:50/156 || Total Loss: 44.4666 || 1.5388s/step\n",
            "step:60/156 || Total Loss: 42.9963 || 1.7073s/step\n",
            "step:70/156 || Total Loss: 41.3694 || 1.6970s/step\n",
            "step:80/156 || Total Loss: 45.9770 || 1.6417s/step\n",
            "step:90/156 || Total Loss: 44.4795 || 1.7006s/step\n",
            "step:100/156 || Total Loss: 46.1705 || 1.7663s/step\n",
            "step:110/156 || Total Loss: 45.6325 || 1.7818s/step\n",
            "step:120/156 || Total Loss: 45.9877 || 1.3919s/step\n",
            "step:130/156 || Total Loss: 45.7875 || 1.7681s/step\n",
            "step:140/156 || Total Loss: 44.5612 || 1.4185s/step\n",
            "step:150/156 || Total Loss: 44.3986 || 2.1068s/step\n",
            "Finish Training.\n",
            "Total Loss: 43.6545 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:8/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 37.5212 || 1.5814s/step\n",
            "step:10/156 || Total Loss: 46.4939 || 1.6458s/step\n",
            "step:20/156 || Total Loss: 40.4390 || 2.0177s/step\n",
            "step:30/156 || Total Loss: 36.5798 || 1.5521s/step\n",
            "step:40/156 || Total Loss: 35.2619 || 1.5991s/step\n",
            "step:50/156 || Total Loss: 33.6253 || 1.5328s/step\n",
            "step:60/156 || Total Loss: 33.9354 || 1.6896s/step\n",
            "step:70/156 || Total Loss: 35.6929 || 1.6862s/step\n",
            "step:80/156 || Total Loss: 34.8346 || 1.5712s/step\n",
            "step:90/156 || Total Loss: 33.7043 || 1.6174s/step\n",
            "step:100/156 || Total Loss: 32.9942 || 1.5123s/step\n",
            "step:110/156 || Total Loss: 33.3194 || 1.8769s/step\n",
            "step:120/156 || Total Loss: 33.8646 || 1.4764s/step\n",
            "step:130/156 || Total Loss: 33.2623 || 1.6291s/step\n",
            "step:140/156 || Total Loss: 32.9439 || 1.5208s/step\n",
            "step:150/156 || Total Loss: 33.3698 || 1.7848s/step\n",
            "Finish Training.\n",
            "Total Loss: 33.3832 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:9/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 26.9251 || 1.5749s/step\n",
            "step:10/156 || Total Loss: 26.6151 || 1.8509s/step\n",
            "step:20/156 || Total Loss: 28.6459 || 1.5765s/step\n",
            "step:30/156 || Total Loss: 33.5702 || 1.3987s/step\n",
            "step:40/156 || Total Loss: 33.1604 || 1.7232s/step\n",
            "step:50/156 || Total Loss: 30.8679 || 1.3911s/step\n",
            "step:60/156 || Total Loss: 31.4420 || 1.7725s/step\n",
            "step:70/156 || Total Loss: 32.4034 || 1.6366s/step\n",
            "step:80/156 || Total Loss: 31.2723 || 1.5975s/step\n",
            "step:90/156 || Total Loss: 31.4457 || 1.9808s/step\n",
            "step:100/156 || Total Loss: 33.5036 || 1.8960s/step\n",
            "step:110/156 || Total Loss: 33.1553 || 1.6291s/step\n",
            "step:120/156 || Total Loss: 32.5415 || 1.6025s/step\n",
            "step:130/156 || Total Loss: 33.2728 || 1.6853s/step\n",
            "step:140/156 || Total Loss: 34.7246 || 1.7540s/step\n",
            "step:150/156 || Total Loss: 35.0804 || 2.4954s/step\n",
            "Finish Training.\n",
            "Total Loss: 35.0903 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:10/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 204.8470 || 1.9406s/step\n",
            "step:10/156 || Total Loss: 53.1820 || 1.5947s/step\n",
            "step:20/156 || Total Loss: 37.6087 || 1.4002s/step\n",
            "step:30/156 || Total Loss: 34.6211 || 1.6149s/step\n",
            "step:40/156 || Total Loss: 31.7290 || 1.4814s/step\n",
            "step:50/156 || Total Loss: 29.6636 || 1.3340s/step\n",
            "step:60/156 || Total Loss: 28.9841 || 1.7280s/step\n",
            "step:70/156 || Total Loss: 29.6652 || 1.3429s/step\n",
            "step:80/156 || Total Loss: 28.8573 || 1.7267s/step\n",
            "step:90/156 || Total Loss: 28.2900 || 1.7677s/step\n",
            "step:100/156 || Total Loss: 28.5986 || 1.4815s/step\n",
            "step:110/156 || Total Loss: 28.4296 || 1.4615s/step\n",
            "step:120/156 || Total Loss: 28.1271 || 1.4489s/step\n",
            "step:130/156 || Total Loss: 28.3650 || 1.5985s/step\n",
            "step:140/156 || Total Loss: 27.6016 || 1.5054s/step\n",
            "step:150/156 || Total Loss: 26.9196 || 1.7203s/step\n",
            "Finish Training.\n",
            "Total Loss: 26.6155 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:11/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 27.7557 || 1.6625s/step\n",
            "step:10/156 || Total Loss: 27.2434 || 1.5934s/step\n",
            "step:20/156 || Total Loss: 33.4489 || 1.7950s/step\n",
            "step:30/156 || Total Loss: 28.9849 || 1.5914s/step\n",
            "step:40/156 || Total Loss: 28.0309 || 1.4712s/step\n",
            "step:50/156 || Total Loss: 31.9852 || 1.5568s/step\n",
            "step:60/156 || Total Loss: 31.3066 || 1.3948s/step\n",
            "step:70/156 || Total Loss: 30.2790 || 1.5452s/step\n",
            "step:80/156 || Total Loss: 28.9683 || 1.7034s/step\n",
            "step:90/156 || Total Loss: 29.7689 || 2.2600s/step\n",
            "step:100/156 || Total Loss: 28.3631 || 1.5093s/step\n",
            "step:110/156 || Total Loss: 27.8877 || 1.3787s/step\n",
            "step:120/156 || Total Loss: 28.5439 || 1.4203s/step\n",
            "step:130/156 || Total Loss: 28.8055 || 2.0461s/step\n",
            "step:140/156 || Total Loss: 30.6714 || 1.5454s/step\n",
            "step:150/156 || Total Loss: 29.9782 || 1.4933s/step\n",
            "Finish Training.\n",
            "Total Loss: 29.6927 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:12/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 21.9312 || 1.4673s/step\n",
            "step:10/156 || Total Loss: 26.9446 || 1.9394s/step\n",
            "step:20/156 || Total Loss: 25.3190 || 1.4729s/step\n",
            "step:30/156 || Total Loss: 30.6020 || 1.6339s/step\n",
            "step:40/156 || Total Loss: 31.4969 || 1.4692s/step\n",
            "step:50/156 || Total Loss: 29.7425 || 1.5545s/step\n",
            "step:60/156 || Total Loss: 29.7534 || 1.5951s/step\n",
            "step:70/156 || Total Loss: 28.2933 || 1.7359s/step\n",
            "step:80/156 || Total Loss: 27.0228 || 1.3884s/step\n",
            "step:90/156 || Total Loss: 25.7332 || 1.8155s/step\n",
            "step:100/156 || Total Loss: 24.9262 || 1.5785s/step\n",
            "step:110/156 || Total Loss: 24.2609 || 1.6206s/step\n",
            "step:120/156 || Total Loss: 23.7119 || 1.5402s/step\n",
            "step:130/156 || Total Loss: 23.3867 || 1.6585s/step\n",
            "step:140/156 || Total Loss: 23.0683 || 1.4532s/step\n",
            "step:150/156 || Total Loss: 23.4016 || 1.4357s/step\n",
            "Finish Training.\n",
            "Total Loss: 23.2434 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:13/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 11.1195 || 1.5714s/step\n",
            "step:10/156 || Total Loss: 18.2887 || 1.5567s/step\n",
            "step:20/156 || Total Loss: 18.2046 || 1.8158s/step\n",
            "step:30/156 || Total Loss: 21.4723 || 1.6091s/step\n",
            "step:40/156 || Total Loss: 22.9830 || 1.8205s/step\n",
            "step:50/156 || Total Loss: 24.7762 || 2.4979s/step\n",
            "step:60/156 || Total Loss: 24.0052 || 1.5228s/step\n",
            "step:70/156 || Total Loss: 24.0965 || 1.3108s/step\n",
            "step:80/156 || Total Loss: 23.8373 || 1.8333s/step\n",
            "step:90/156 || Total Loss: 25.2356 || 1.6772s/step\n",
            "step:100/156 || Total Loss: 25.3219 || 1.8633s/step\n",
            "step:110/156 || Total Loss: 25.6919 || 1.6733s/step\n",
            "step:120/156 || Total Loss: 25.1105 || 1.7080s/step\n",
            "step:130/156 || Total Loss: 26.2360 || 1.5888s/step\n",
            "step:140/156 || Total Loss: 26.0544 || 1.4522s/step\n",
            "step:150/156 || Total Loss: 25.6599 || 1.5060s/step\n",
            "Finish Training.\n",
            "Total Loss: 24.9516 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:14/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 13.1612 || 1.4960s/step\n",
            "step:10/156 || Total Loss: 27.4709 || 1.4816s/step\n",
            "step:20/156 || Total Loss: 26.4368 || 1.4150s/step\n",
            "step:30/156 || Total Loss: 25.3158 || 1.6018s/step\n",
            "step:40/156 || Total Loss: 24.2708 || 1.3333s/step\n",
            "step:50/156 || Total Loss: 23.8279 || 1.5168s/step\n",
            "step:60/156 || Total Loss: 22.4867 || 1.7648s/step\n",
            "step:70/156 || Total Loss: 22.4167 || 1.3742s/step\n",
            "step:80/156 || Total Loss: 21.6932 || 1.5311s/step\n",
            "step:90/156 || Total Loss: 20.9977 || 1.7490s/step\n",
            "step:100/156 || Total Loss: 20.6147 || 1.5969s/step\n",
            "step:110/156 || Total Loss: 20.7356 || 1.6173s/step\n",
            "step:120/156 || Total Loss: 20.5226 || 1.3491s/step\n",
            "step:130/156 || Total Loss: 20.2717 || 1.5971s/step\n",
            "step:140/156 || Total Loss: 19.9669 || 1.5271s/step\n",
            "step:150/156 || Total Loss: 20.0730 || 1.5710s/step\n",
            "Finish Training.\n",
            "Total Loss: 20.2136 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:15/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 9.9429 || 1.4707s/step\n",
            "step:10/156 || Total Loss: 20.3086 || 1.6958s/step\n",
            "step:20/156 || Total Loss: 18.5692 || 1.4563s/step\n",
            "step:30/156 || Total Loss: 26.2650 || 1.5014s/step\n",
            "step:40/156 || Total Loss: 26.8402 || 1.4315s/step\n",
            "step:50/156 || Total Loss: 26.0320 || 1.4886s/step\n",
            "step:60/156 || Total Loss: 27.4173 || 1.5412s/step\n",
            "step:70/156 || Total Loss: 25.5843 || 1.6352s/step\n",
            "step:80/156 || Total Loss: 24.4296 || 1.6004s/step\n",
            "step:90/156 || Total Loss: 25.0048 || 1.5786s/step\n",
            "step:100/156 || Total Loss: 24.2337 || 1.8584s/step\n",
            "step:110/156 || Total Loss: 23.4827 || 1.3586s/step\n",
            "step:120/156 || Total Loss: 22.8680 || 1.6307s/step\n",
            "step:130/156 || Total Loss: 23.3640 || 1.5055s/step\n",
            "step:140/156 || Total Loss: 23.5575 || 2.0998s/step\n",
            "step:150/156 || Total Loss: 23.1660 || 1.5680s/step\n",
            "Finish Training.\n",
            "Total Loss: 22.8464 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:16/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 26.7026 || 1.5918s/step\n",
            "step:10/156 || Total Loss: 19.6348 || 1.5981s/step\n",
            "step:20/156 || Total Loss: 17.8168 || 1.6371s/step\n",
            "step:30/156 || Total Loss: 18.2572 || 1.3455s/step\n",
            "step:40/156 || Total Loss: 20.5016 || 1.4104s/step\n",
            "step:50/156 || Total Loss: 21.7441 || 1.7739s/step\n",
            "step:60/156 || Total Loss: 21.1130 || 1.8099s/step\n",
            "step:70/156 || Total Loss: 20.6803 || 1.9098s/step\n",
            "step:80/156 || Total Loss: 22.2901 || 1.5826s/step\n",
            "step:90/156 || Total Loss: 22.5447 || 1.4244s/step\n",
            "step:100/156 || Total Loss: 21.4126 || 1.7906s/step\n",
            "step:110/156 || Total Loss: 21.2180 || 1.6175s/step\n",
            "step:120/156 || Total Loss: 20.4167 || 1.4937s/step\n",
            "step:130/156 || Total Loss: 20.7811 || 1.8294s/step\n",
            "step:140/156 || Total Loss: 20.5141 || 1.5225s/step\n",
            "step:150/156 || Total Loss: 20.3780 || 1.5598s/step\n",
            "Finish Training.\n",
            "Total Loss: 20.1219 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:17/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 8.1238 || 1.3997s/step\n",
            "step:10/156 || Total Loss: 16.6566 || 1.6261s/step\n",
            "step:20/156 || Total Loss: 16.9294 || 1.5299s/step\n",
            "step:30/156 || Total Loss: 20.0720 || 1.5280s/step\n",
            "step:40/156 || Total Loss: 19.2028 || 1.5099s/step\n",
            "step:50/156 || Total Loss: 19.2833 || 1.5041s/step\n",
            "step:60/156 || Total Loss: 21.6395 || 1.5472s/step\n",
            "step:70/156 || Total Loss: 22.2872 || 1.4285s/step\n",
            "step:80/156 || Total Loss: 22.5639 || 1.5848s/step\n",
            "step:90/156 || Total Loss: 22.4157 || 2.1602s/step\n",
            "step:100/156 || Total Loss: 21.6712 || 1.3394s/step\n",
            "step:110/156 || Total Loss: 21.9054 || 1.5091s/step\n",
            "step:120/156 || Total Loss: 21.4747 || 1.5718s/step\n",
            "step:130/156 || Total Loss: 21.1571 || 1.6558s/step\n",
            "step:140/156 || Total Loss: 21.1197 || 1.3504s/step\n",
            "step:150/156 || Total Loss: 21.0816 || 1.3708s/step\n",
            "Finish Training.\n",
            "Total Loss: 22.3328 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:18/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 9.3149 || 1.3849s/step\n",
            "step:10/156 || Total Loss: 35.3549 || 1.9648s/step\n",
            "step:20/156 || Total Loss: 31.0502 || 1.6811s/step\n",
            "step:30/156 || Total Loss: 26.3743 || 1.7989s/step\n",
            "step:40/156 || Total Loss: 24.0699 || 1.5424s/step\n",
            "step:50/156 || Total Loss: 23.6571 || 1.8103s/step\n",
            "step:60/156 || Total Loss: 22.8213 || 1.4953s/step\n",
            "step:70/156 || Total Loss: 23.5388 || 1.7389s/step\n",
            "step:80/156 || Total Loss: 23.2113 || 1.4481s/step\n",
            "step:90/156 || Total Loss: 22.2703 || 1.6738s/step\n",
            "step:100/156 || Total Loss: 21.1632 || 1.5008s/step\n",
            "step:110/156 || Total Loss: 21.6873 || 1.5359s/step\n",
            "step:120/156 || Total Loss: 20.8236 || 1.6740s/step\n",
            "step:130/156 || Total Loss: 20.5442 || 1.3737s/step\n",
            "step:140/156 || Total Loss: 20.5969 || 1.3949s/step\n",
            "step:150/156 || Total Loss: 20.0407 || 1.9932s/step\n",
            "Finish Training.\n",
            "Total Loss: 19.6046 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:19/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 7.6442 || 1.4729s/step\n",
            "step:10/156 || Total Loss: 9.9857 || 1.9916s/step\n",
            "step:20/156 || Total Loss: 17.5120 || 1.6151s/step\n",
            "step:30/156 || Total Loss: 17.4742 || 1.5989s/step\n",
            "step:40/156 || Total Loss: 21.1166 || 1.3412s/step\n",
            "step:50/156 || Total Loss: 19.4535 || 2.0383s/step\n",
            "step:60/156 || Total Loss: 18.7781 || 1.5612s/step\n",
            "step:70/156 || Total Loss: 19.1877 || 1.8287s/step\n",
            "step:80/156 || Total Loss: 19.8309 || 1.6273s/step\n",
            "step:90/156 || Total Loss: 19.3880 || 1.4945s/step\n",
            "step:100/156 || Total Loss: 18.8923 || 1.4046s/step\n",
            "step:110/156 || Total Loss: 19.3203 || 1.7754s/step\n",
            "step:120/156 || Total Loss: 19.0607 || 1.6410s/step\n",
            "step:130/156 || Total Loss: 19.1760 || 1.7946s/step\n",
            "step:140/156 || Total Loss: 19.4183 || 1.4543s/step\n",
            "step:150/156 || Total Loss: 20.2389 || 1.3274s/step\n",
            "Finish Training.\n",
            "Total Loss: 20.1108 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:20/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 17.3854 || 1.7898s/step\n",
            "step:10/156 || Total Loss: 19.9086 || 1.5125s/step\n",
            "step:20/156 || Total Loss: 29.1040 || 1.4940s/step\n",
            "step:30/156 || Total Loss: 25.1512 || 2.0919s/step\n",
            "step:40/156 || Total Loss: 21.8927 || 1.6233s/step\n",
            "step:50/156 || Total Loss: 20.2851 || 1.9101s/step\n",
            "step:60/156 || Total Loss: 20.6567 || 1.6248s/step\n",
            "step:70/156 || Total Loss: 20.2782 || 1.6593s/step\n",
            "step:80/156 || Total Loss: 21.0529 || 1.5755s/step\n",
            "step:90/156 || Total Loss: 21.5332 || 1.9586s/step\n",
            "step:100/156 || Total Loss: 21.9585 || 1.5523s/step\n",
            "step:110/156 || Total Loss: 20.9277 || 1.5895s/step\n",
            "step:120/156 || Total Loss: 20.4514 || 1.5299s/step\n",
            "step:130/156 || Total Loss: 19.7594 || 1.5259s/step\n",
            "step:140/156 || Total Loss: 19.3601 || 1.6272s/step\n",
            "step:150/156 || Total Loss: 19.3533 || 1.7445s/step\n",
            "Finish Training.\n",
            "Total Loss: 18.9133 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:21/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 12.5376 || 1.7863s/step\n",
            "step:10/156 || Total Loss: 24.1680 || 1.4643s/step\n",
            "step:20/156 || Total Loss: 21.5126 || 1.5188s/step\n",
            "step:30/156 || Total Loss: 18.6180 || 1.6966s/step\n",
            "step:40/156 || Total Loss: 17.9823 || 1.5576s/step\n",
            "step:50/156 || Total Loss: 19.2694 || 1.8883s/step\n",
            "step:60/156 || Total Loss: 17.6940 || 1.6640s/step\n",
            "step:70/156 || Total Loss: 17.3151 || 1.7538s/step\n",
            "step:80/156 || Total Loss: 17.0068 || 1.5762s/step\n",
            "step:90/156 || Total Loss: 16.9086 || 1.8209s/step\n",
            "step:100/156 || Total Loss: 16.6983 || 1.6439s/step\n",
            "step:110/156 || Total Loss: 16.3075 || 1.8643s/step\n",
            "step:120/156 || Total Loss: 16.6623 || 1.4186s/step\n",
            "step:130/156 || Total Loss: 17.7649 || 2.1589s/step\n",
            "step:140/156 || Total Loss: 19.7260 || 1.6014s/step\n",
            "step:150/156 || Total Loss: 19.3540 || 1.4706s/step\n",
            "Finish Training.\n",
            "Total Loss: 19.5443 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:22/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 54.9824 || 1.7429s/step\n",
            "step:10/156 || Total Loss: 29.6459 || 1.5155s/step\n",
            "step:20/156 || Total Loss: 20.7541 || 1.5179s/step\n",
            "step:30/156 || Total Loss: 17.6486 || 1.7396s/step\n",
            "step:40/156 || Total Loss: 19.6528 || 1.6377s/step\n",
            "step:50/156 || Total Loss: 19.3491 || 1.4668s/step\n",
            "step:60/156 || Total Loss: 19.3625 || 1.6669s/step\n",
            "step:70/156 || Total Loss: 19.4684 || 1.7426s/step\n",
            "step:80/156 || Total Loss: 19.7817 || 1.7020s/step\n",
            "step:90/156 || Total Loss: 19.4008 || 1.7621s/step\n",
            "step:100/156 || Total Loss: 18.6429 || 1.9490s/step\n",
            "step:110/156 || Total Loss: 17.8503 || 1.7548s/step\n",
            "step:120/156 || Total Loss: 17.7267 || 1.5163s/step\n",
            "step:130/156 || Total Loss: 18.0749 || 1.6075s/step\n",
            "step:140/156 || Total Loss: 18.2871 || 1.6574s/step\n",
            "step:150/156 || Total Loss: 17.7324 || 1.4384s/step\n",
            "Finish Training.\n",
            "Total Loss: 17.5018 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:23/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 6.1475 || 1.4649s/step\n",
            "step:10/156 || Total Loss: 13.2695 || 1.6797s/step\n",
            "step:20/156 || Total Loss: 13.8326 || 2.2845s/step\n",
            "step:30/156 || Total Loss: 19.3385 || 1.6349s/step\n",
            "step:40/156 || Total Loss: 17.8120 || 1.4118s/step\n",
            "step:50/156 || Total Loss: 18.0860 || 1.6387s/step\n",
            "step:60/156 || Total Loss: 17.7393 || 1.7711s/step\n",
            "step:70/156 || Total Loss: 17.7884 || 1.8596s/step\n",
            "step:80/156 || Total Loss: 17.5206 || 1.5881s/step\n",
            "step:90/156 || Total Loss: 16.8869 || 1.8433s/step\n",
            "step:100/156 || Total Loss: 16.5216 || 1.6646s/step\n",
            "step:110/156 || Total Loss: 16.8731 || 1.8201s/step\n",
            "step:120/156 || Total Loss: 16.4292 || 1.6328s/step\n",
            "step:130/156 || Total Loss: 16.6009 || 1.5324s/step\n",
            "step:140/156 || Total Loss: 17.1608 || 1.4974s/step\n",
            "step:150/156 || Total Loss: 17.5231 || 1.8043s/step\n",
            "Finish Training.\n",
            "Total Loss: 17.3014 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:24/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 36.9097 || 1.7508s/step\n",
            "step:10/156 || Total Loss: 11.9073 || 1.7494s/step\n",
            "step:20/156 || Total Loss: 13.8697 || 1.3518s/step\n",
            "step:30/156 || Total Loss: 14.6478 || 1.7853s/step\n",
            "step:40/156 || Total Loss: 15.4978 || 1.7937s/step\n",
            "step:50/156 || Total Loss: 16.1544 || 1.6545s/step\n",
            "step:60/156 || Total Loss: 17.0436 || 1.4824s/step\n",
            "step:70/156 || Total Loss: 16.8050 || 1.7182s/step\n",
            "step:80/156 || Total Loss: 18.4213 || 1.9726s/step\n",
            "step:90/156 || Total Loss: 17.9198 || 1.5477s/step\n",
            "step:100/156 || Total Loss: 18.0134 || 1.6854s/step\n",
            "step:110/156 || Total Loss: 20.7852 || 1.5660s/step\n",
            "step:120/156 || Total Loss: 20.0584 || 1.5154s/step\n",
            "step:130/156 || Total Loss: 19.4883 || 1.4909s/step\n",
            "step:140/156 || Total Loss: 18.9852 || 1.6057s/step\n",
            "step:150/156 || Total Loss: 18.6599 || 1.6267s/step\n",
            "Finish Training.\n",
            "Total Loss: 18.6590 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:25/25\n",
            "Start Training.\n",
            "step:1/156 || Total Loss: 10.5448 || 1.5300s/step\n",
            "step:10/156 || Total Loss: 38.8383 || 1.5304s/step\n",
            "step:20/156 || Total Loss: 34.9072 || 1.4385s/step\n",
            "step:30/156 || Total Loss: 28.5129 || 1.4933s/step\n",
            "step:40/156 || Total Loss: 25.1043 || 1.4787s/step\n",
            "step:50/156 || Total Loss: 22.8703 || 1.4361s/step\n",
            "step:60/156 || Total Loss: 21.6856 || 2.0788s/step\n",
            "step:70/156 || Total Loss: 20.6641 || 1.4572s/step\n",
            "step:80/156 || Total Loss: 20.1670 || 1.8896s/step\n",
            "step:90/156 || Total Loss: 20.0884 || 1.8945s/step\n",
            "step:100/156 || Total Loss: 19.9156 || 1.8923s/step\n",
            "step:110/156 || Total Loss: 20.1936 || 1.6839s/step\n",
            "step:120/156 || Total Loss: 19.6602 || 1.5696s/step\n",
            "step:130/156 || Total Loss: 18.9460 || 1.7698s/step\n",
            "step:140/156 || Total Loss: 18.6645 || 2.5287s/step\n",
            "step:150/156 || Total Loss: 18.4522 || 1.4835s/step\n",
            "Finish Training.\n",
            "Total Loss: 18.3301 || Val Loss: 0.0000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mn6h64xNWfL5",
        "colab_type": "code",
        "outputId": "15b5955c-373a-40b0-8baf-60ef894fe493",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "#------------------------------------#\n",
        "#   解冻backbone后训练\n",
        "#------------------------------------#\n",
        "lr = 1e-4\n",
        "Batch_size = 2\n",
        "Freeze_Epoch = 25\n",
        "Unfreeze_Epoch = 50\n",
        "\n",
        "optimizer = optim.Adam(net.parameters(), lr, weight_decay=5e-4)\n",
        "if Cosine_lr:\n",
        "    lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=5, eta_min=1e-5)\n",
        "else:\n",
        "    lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=1, gamma=0.9)\n",
        "\n",
        "gen = Generator(Batch_size, train_lines, (input_shape[0], input_shape[1])).generate(mosaic = mosaic)\n",
        "gen_val = Generator(Batch_size, val_lines, (input_shape[0], input_shape[1])).generate(mosaic = False)\n",
        "                        \n",
        "epoch_size = int(max(1, num_train//Batch_size//2.5)) if mosaic else max(1, num_train//Batch_size)\n",
        "epoch_size_val = num_val//Batch_size\n",
        "for param in model.backbone.parameters():\n",
        "    param.requires_grad = True\n",
        "\n",
        "for epoch in range(Freeze_Epoch, Unfreeze_Epoch):\n",
        "    total_loss, val_loss = fit_one_epoch(net, yolo_losses, epoch, epoch_size, epoch_size_val, gen, gen_val, \n",
        "                                         Unfreeze_Epoch, Cuda, optimizer, lr_scheduler)\n",
        "    if total_loss < best_loss:\n",
        "        best_loss = total_loss\n",
        "        best_model_weights = copy.deepcopy(model.state_dict())\n",
        "    with open('/content/gdrive/My Drive/cv_final/yolo_pytorch/total_loss.csv', mode='a+') as total_loss_file:\n",
        "        total_loss_file.write(str(total_loss.item()) + '\\n')\n",
        "    #with open('val_loss.csv', mode='a+') as val_loss_file:\n",
        "    #    val_loss_file.write(str(val_loss.item() + '\\n')\n",
        "torch.save(best_model_weights, '/content/gdrive/My Drive/cv_final/yolo_pytorch/model_data/yolov4_maskdetect_weights2.pth')"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:26/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 4.6206 || 3.1176s/step\n",
            "step:10/314 || Total Loss: 9.4760 || 1.2708s/step\n",
            "step:20/314 || Total Loss: 12.7913 || 1.4088s/step\n",
            "step:30/314 || Total Loss: 16.3511 || 1.2552s/step\n",
            "step:40/314 || Total Loss: 14.3990 || 0.9748s/step\n",
            "step:50/314 || Total Loss: 15.3550 || 1.1698s/step\n",
            "step:60/314 || Total Loss: 20.4270 || 0.9885s/step\n",
            "step:70/314 || Total Loss: 19.4796 || 0.9272s/step\n",
            "step:80/314 || Total Loss: 19.5500 || 0.9957s/step\n",
            "step:90/314 || Total Loss: 18.9360 || 1.1941s/step\n",
            "step:100/314 || Total Loss: 17.9444 || 1.0547s/step\n",
            "step:110/314 || Total Loss: 19.0011 || 1.4117s/step\n",
            "step:120/314 || Total Loss: 19.1521 || 1.2620s/step\n",
            "step:130/314 || Total Loss: 18.7055 || 1.0698s/step\n",
            "step:140/314 || Total Loss: 18.3629 || 1.2491s/step\n",
            "step:150/314 || Total Loss: 18.0807 || 1.0976s/step\n",
            "step:160/314 || Total Loss: 18.0218 || 1.1010s/step\n",
            "step:170/314 || Total Loss: 17.6584 || 1.1914s/step\n",
            "step:180/314 || Total Loss: 17.8128 || 1.0245s/step\n",
            "step:190/314 || Total Loss: 17.5483 || 1.0131s/step\n",
            "step:200/314 || Total Loss: 16.9324 || 0.9878s/step\n",
            "step:210/314 || Total Loss: 17.0273 || 1.0324s/step\n",
            "step:220/314 || Total Loss: 16.8099 || 0.9760s/step\n",
            "step:230/314 || Total Loss: 16.4565 || 1.0543s/step\n",
            "step:240/314 || Total Loss: 16.3787 || 1.0165s/step\n",
            "step:250/314 || Total Loss: 16.2580 || 1.0497s/step\n",
            "step:260/314 || Total Loss: 15.8736 || 1.1023s/step\n",
            "step:270/314 || Total Loss: 15.5808 || 1.0424s/step\n",
            "step:280/314 || Total Loss: 16.0778 || 0.9562s/step\n",
            "step:290/314 || Total Loss: 15.7762 || 1.0359s/step\n",
            "step:300/314 || Total Loss: 15.5400 || 1.4052s/step\n",
            "step:310/314 || Total Loss: 15.8148 || 1.1039s/step\n",
            "Finish Training.\n",
            "Total Loss: 15.6949 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:27/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 54.8562 || 1.2458s/step\n",
            "step:10/314 || Total Loss: 24.8557 || 1.1307s/step\n",
            "step:20/314 || Total Loss: 19.4580 || 1.2140s/step\n",
            "step:30/314 || Total Loss: 18.7107 || 1.1678s/step\n",
            "step:40/314 || Total Loss: 15.8071 || 1.0847s/step\n",
            "step:50/314 || Total Loss: 14.0294 || 1.1160s/step\n",
            "step:60/314 || Total Loss: 13.4220 || 1.1104s/step\n",
            "step:70/314 || Total Loss: 13.2665 || 1.2828s/step\n",
            "step:80/314 || Total Loss: 13.6563 || 1.2599s/step\n",
            "step:90/314 || Total Loss: 13.6351 || 1.0166s/step\n",
            "step:100/314 || Total Loss: 13.3266 || 1.3184s/step\n",
            "step:110/314 || Total Loss: 13.0793 || 1.2096s/step\n",
            "step:120/314 || Total Loss: 12.7031 || 1.0678s/step\n",
            "step:130/314 || Total Loss: 12.1290 || 1.1247s/step\n",
            "step:140/314 || Total Loss: 12.4666 || 1.0767s/step\n",
            "step:150/314 || Total Loss: 12.3368 || 1.0556s/step\n",
            "step:160/314 || Total Loss: 12.2771 || 1.0503s/step\n",
            "step:170/314 || Total Loss: 12.4363 || 1.1734s/step\n",
            "step:180/314 || Total Loss: 12.2299 || 1.0252s/step\n",
            "step:190/314 || Total Loss: 12.2935 || 1.1701s/step\n",
            "step:200/314 || Total Loss: 12.1337 || 1.1080s/step\n",
            "step:210/314 || Total Loss: 12.0344 || 1.0593s/step\n",
            "step:220/314 || Total Loss: 12.0635 || 1.0210s/step\n",
            "step:230/314 || Total Loss: 11.9363 || 1.1975s/step\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/PIL/TiffImagePlugin.py:788: UserWarning: Corrupt EXIF data.  Expecting to read 4 bytes but only got 0. \n",
            "  warnings.warn(str(msg))\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "step:240/314 || Total Loss: 11.8239 || 0.9901s/step\n",
            "step:250/314 || Total Loss: 14.3533 || 1.1296s/step\n",
            "step:260/314 || Total Loss: 14.1937 || 1.0173s/step\n",
            "step:270/314 || Total Loss: 13.8998 || 1.0331s/step\n",
            "step:280/314 || Total Loss: 13.7632 || 1.1187s/step\n",
            "step:290/314 || Total Loss: 13.6149 || 0.9880s/step\n",
            "step:300/314 || Total Loss: 13.6845 || 1.0673s/step\n",
            "step:310/314 || Total Loss: 13.5664 || 1.0254s/step\n",
            "Finish Training.\n",
            "Total Loss: 13.5754 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:28/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 13.5887 || 1.1854s/step\n",
            "step:10/314 || Total Loss: 10.4720 || 1.0117s/step\n",
            "step:20/314 || Total Loss: 10.0551 || 1.2411s/step\n",
            "step:30/314 || Total Loss: 14.9193 || 1.3820s/step\n",
            "step:40/314 || Total Loss: 13.0941 || 1.0051s/step\n",
            "step:50/314 || Total Loss: 13.3436 || 1.0454s/step\n",
            "step:60/314 || Total Loss: 13.2685 || 1.3045s/step\n",
            "step:70/314 || Total Loss: 13.7265 || 1.0956s/step\n",
            "step:80/314 || Total Loss: 13.2139 || 0.9762s/step\n",
            "step:90/314 || Total Loss: 13.1406 || 1.0613s/step\n",
            "step:100/314 || Total Loss: 15.3900 || 1.0694s/step\n",
            "step:110/314 || Total Loss: 15.1964 || 1.2323s/step\n",
            "step:120/314 || Total Loss: 14.5038 || 0.9619s/step\n",
            "step:130/314 || Total Loss: 14.5064 || 1.0469s/step\n",
            "step:140/314 || Total Loss: 14.2190 || 1.1215s/step\n",
            "step:150/314 || Total Loss: 14.1952 || 1.0422s/step\n",
            "step:160/314 || Total Loss: 13.9174 || 1.0106s/step\n",
            "step:170/314 || Total Loss: 13.7128 || 1.1914s/step\n",
            "step:180/314 || Total Loss: 14.4558 || 1.0563s/step\n",
            "step:190/314 || Total Loss: 14.4086 || 1.1098s/step\n",
            "step:200/314 || Total Loss: 13.9981 || 1.3253s/step\n",
            "step:210/314 || Total Loss: 14.1414 || 1.2851s/step\n",
            "step:220/314 || Total Loss: 14.4806 || 0.9751s/step\n",
            "step:230/314 || Total Loss: 14.7183 || 1.0928s/step\n",
            "step:240/314 || Total Loss: 14.6501 || 1.2188s/step\n",
            "step:250/314 || Total Loss: 14.5010 || 1.2832s/step\n",
            "step:260/314 || Total Loss: 14.3654 || 1.0237s/step\n",
            "step:270/314 || Total Loss: 14.2739 || 1.1351s/step\n",
            "step:280/314 || Total Loss: 14.4067 || 1.1304s/step\n",
            "step:290/314 || Total Loss: 14.2319 || 1.0679s/step\n",
            "step:300/314 || Total Loss: 14.1166 || 0.9902s/step\n",
            "step:310/314 || Total Loss: 14.0864 || 1.2253s/step\n",
            "Finish Training.\n",
            "Total Loss: 14.1124 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:29/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 13.1801 || 1.1328s/step\n",
            "step:10/314 || Total Loss: 9.6033 || 1.0963s/step\n",
            "step:20/314 || Total Loss: 12.0992 || 1.2830s/step\n",
            "step:30/314 || Total Loss: 19.5233 || 1.2206s/step\n",
            "step:40/314 || Total Loss: 16.3010 || 1.0189s/step\n",
            "step:50/314 || Total Loss: 14.3797 || 1.0525s/step\n",
            "step:60/314 || Total Loss: 15.0216 || 1.0933s/step\n",
            "step:70/314 || Total Loss: 14.0946 || 1.0410s/step\n",
            "step:80/314 || Total Loss: 15.2253 || 1.0184s/step\n",
            "step:90/314 || Total Loss: 14.0573 || 1.1821s/step\n",
            "step:100/314 || Total Loss: 14.1803 || 1.1590s/step\n",
            "step:110/314 || Total Loss: 13.7032 || 1.0864s/step\n",
            "step:120/314 || Total Loss: 13.7148 || 1.0572s/step\n",
            "step:130/314 || Total Loss: 13.5069 || 1.0834s/step\n",
            "step:140/314 || Total Loss: 13.1314 || 1.1136s/step\n",
            "step:150/314 || Total Loss: 13.0701 || 1.1149s/step\n",
            "step:160/314 || Total Loss: 12.7741 || 1.1086s/step\n",
            "step:170/314 || Total Loss: 12.4473 || 1.1510s/step\n",
            "step:180/314 || Total Loss: 13.1674 || 1.0384s/step\n",
            "step:190/314 || Total Loss: 12.7681 || 1.0729s/step\n",
            "step:200/314 || Total Loss: 12.6858 || 1.1912s/step\n",
            "step:210/314 || Total Loss: 12.4977 || 1.0412s/step\n",
            "step:220/314 || Total Loss: 12.3836 || 1.3150s/step\n",
            "step:230/314 || Total Loss: 12.1756 || 1.0531s/step\n",
            "step:240/314 || Total Loss: 12.0812 || 1.0562s/step\n",
            "step:250/314 || Total Loss: 12.2369 || 1.2709s/step\n",
            "step:260/314 || Total Loss: 12.4691 || 0.9798s/step\n",
            "step:270/314 || Total Loss: 12.7282 || 1.2739s/step\n",
            "step:280/314 || Total Loss: 12.5560 || 1.0921s/step\n",
            "step:290/314 || Total Loss: 12.4678 || 1.1649s/step\n",
            "step:300/314 || Total Loss: 12.7393 || 0.9890s/step\n",
            "step:310/314 || Total Loss: 12.6759 || 1.0972s/step\n",
            "Finish Training.\n",
            "Total Loss: 13.1385 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:30/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 12.8970 || 1.0792s/step\n",
            "step:10/314 || Total Loss: 9.4379 || 1.0190s/step\n",
            "step:20/314 || Total Loss: 8.1138 || 1.1163s/step\n",
            "step:30/314 || Total Loss: 12.0516 || 1.0958s/step\n",
            "step:40/314 || Total Loss: 16.2238 || 1.1410s/step\n",
            "step:50/314 || Total Loss: 16.4273 || 1.4655s/step\n",
            "step:60/314 || Total Loss: 15.4946 || 1.2388s/step\n",
            "step:70/314 || Total Loss: 15.1287 || 1.1913s/step\n",
            "step:80/314 || Total Loss: 15.7038 || 1.0355s/step\n",
            "step:90/314 || Total Loss: 14.8814 || 0.9767s/step\n",
            "step:100/314 || Total Loss: 14.2338 || 1.1025s/step\n",
            "step:110/314 || Total Loss: 13.4527 || 1.1178s/step\n",
            "step:120/314 || Total Loss: 13.8257 || 1.4799s/step\n",
            "step:130/314 || Total Loss: 14.0547 || 1.1482s/step\n",
            "step:140/314 || Total Loss: 13.7230 || 1.0809s/step\n",
            "step:150/314 || Total Loss: 13.3916 || 1.1251s/step\n",
            "step:160/314 || Total Loss: 13.0404 || 1.0990s/step\n",
            "step:170/314 || Total Loss: 12.7507 || 1.2870s/step\n",
            "step:180/314 || Total Loss: 12.5398 || 1.0618s/step\n",
            "step:190/314 || Total Loss: 12.1332 || 1.0345s/step\n",
            "step:200/314 || Total Loss: 11.8889 || 1.0272s/step\n",
            "step:210/314 || Total Loss: 11.5995 || 1.0733s/step\n",
            "step:220/314 || Total Loss: 11.4157 || 0.9635s/step\n",
            "step:230/314 || Total Loss: 11.1119 || 1.0730s/step\n",
            "step:240/314 || Total Loss: 11.7209 || 1.1143s/step\n",
            "step:250/314 || Total Loss: 11.6193 || 0.9504s/step\n",
            "step:260/314 || Total Loss: 11.6269 || 1.0099s/step\n",
            "step:270/314 || Total Loss: 11.5103 || 1.0466s/step\n",
            "step:280/314 || Total Loss: 11.2902 || 1.0524s/step\n",
            "step:290/314 || Total Loss: 11.1342 || 1.0190s/step\n",
            "step:300/314 || Total Loss: 11.4624 || 1.1801s/step\n",
            "step:310/314 || Total Loss: 11.3422 || 1.0735s/step\n",
            "Finish Training.\n",
            "Total Loss: 11.5525 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:31/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 12.2876 || 1.2564s/step\n",
            "step:10/314 || Total Loss: 11.9683 || 1.1730s/step\n",
            "step:20/314 || Total Loss: 12.1942 || 0.9689s/step\n",
            "step:30/314 || Total Loss: 14.8294 || 1.2887s/step\n",
            "step:40/314 || Total Loss: 13.5284 || 1.0458s/step\n",
            "step:50/314 || Total Loss: 13.5801 || 0.9610s/step\n",
            "step:60/314 || Total Loss: 14.1517 || 1.0048s/step\n",
            "step:70/314 || Total Loss: 14.0908 || 1.1720s/step\n",
            "step:80/314 || Total Loss: 13.3085 || 1.0049s/step\n",
            "step:90/314 || Total Loss: 12.3576 || 1.0727s/step\n",
            "step:100/314 || Total Loss: 11.7631 || 1.0117s/step\n",
            "step:110/314 || Total Loss: 11.5595 || 0.9457s/step\n",
            "step:120/314 || Total Loss: 11.2237 || 1.0728s/step\n",
            "step:130/314 || Total Loss: 10.9643 || 1.0798s/step\n",
            "step:140/314 || Total Loss: 11.4869 || 1.0980s/step\n",
            "step:150/314 || Total Loss: 12.3891 || 0.9326s/step\n",
            "step:160/314 || Total Loss: 12.4385 || 1.0102s/step\n",
            "step:170/314 || Total Loss: 12.3391 || 1.0030s/step\n",
            "step:180/314 || Total Loss: 11.9662 || 1.0363s/step\n",
            "step:190/314 || Total Loss: 11.8461 || 1.1902s/step\n",
            "step:200/314 || Total Loss: 11.8774 || 1.5249s/step\n",
            "step:210/314 || Total Loss: 11.9129 || 1.0619s/step\n",
            "step:220/314 || Total Loss: 11.7380 || 0.9739s/step\n",
            "step:230/314 || Total Loss: 11.6692 || 0.9583s/step\n",
            "step:240/314 || Total Loss: 11.8579 || 1.0353s/step\n",
            "step:250/314 || Total Loss: 11.6403 || 1.2023s/step\n",
            "step:260/314 || Total Loss: 11.4837 || 1.1061s/step\n",
            "step:270/314 || Total Loss: 11.3412 || 0.9891s/step\n",
            "step:280/314 || Total Loss: 11.2698 || 0.9116s/step\n",
            "step:290/314 || Total Loss: 11.1433 || 1.0808s/step\n",
            "step:300/314 || Total Loss: 10.9811 || 1.0890s/step\n",
            "step:310/314 || Total Loss: 10.8965 || 1.1014s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.8044 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:32/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 2.9592 || 0.9979s/step\n",
            "step:10/314 || Total Loss: 8.6085 || 1.1237s/step\n",
            "step:20/314 || Total Loss: 8.1268 || 1.0500s/step\n",
            "step:30/314 || Total Loss: 8.5086 || 1.2278s/step\n",
            "step:40/314 || Total Loss: 10.3335 || 1.1392s/step\n",
            "step:50/314 || Total Loss: 12.5269 || 1.2175s/step\n",
            "step:60/314 || Total Loss: 12.1182 || 1.0671s/step\n",
            "step:70/314 || Total Loss: 11.4390 || 1.0649s/step\n",
            "step:80/314 || Total Loss: 11.3690 || 1.2328s/step\n",
            "step:90/314 || Total Loss: 10.6967 || 1.1495s/step\n",
            "step:100/314 || Total Loss: 10.4038 || 1.0699s/step\n",
            "step:110/314 || Total Loss: 10.0716 || 1.0057s/step\n",
            "step:120/314 || Total Loss: 10.6755 || 1.0693s/step\n",
            "step:130/314 || Total Loss: 10.9177 || 1.1520s/step\n",
            "step:140/314 || Total Loss: 11.4419 || 1.0075s/step\n",
            "step:150/314 || Total Loss: 11.5423 || 1.1357s/step\n",
            "step:160/314 || Total Loss: 11.5281 || 0.9148s/step\n",
            "step:170/314 || Total Loss: 11.5039 || 1.1956s/step\n",
            "step:180/314 || Total Loss: 11.7385 || 0.9518s/step\n",
            "step:190/314 || Total Loss: 12.4848 || 1.0799s/step\n",
            "step:200/314 || Total Loss: 12.7218 || 1.0285s/step\n",
            "step:210/314 || Total Loss: 12.8744 || 1.0960s/step\n",
            "step:220/314 || Total Loss: 12.9357 || 1.0437s/step\n",
            "step:230/314 || Total Loss: 12.5858 || 1.1006s/step\n",
            "step:240/314 || Total Loss: 12.3220 || 1.0647s/step\n",
            "step:250/314 || Total Loss: 12.8228 || 1.0312s/step\n",
            "step:260/314 || Total Loss: 12.6778 || 0.9796s/step\n",
            "step:270/314 || Total Loss: 12.5177 || 0.9229s/step\n",
            "step:280/314 || Total Loss: 12.3692 || 1.0699s/step\n",
            "step:290/314 || Total Loss: 12.4550 || 1.0763s/step\n",
            "step:300/314 || Total Loss: 12.7127 || 1.1370s/step\n",
            "step:310/314 || Total Loss: 12.5916 || 1.0271s/step\n",
            "Finish Training.\n",
            "Total Loss: 12.4219 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:33/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 10.6418 || 1.1233s/step\n",
            "step:10/314 || Total Loss: 9.9089 || 1.1094s/step\n",
            "step:20/314 || Total Loss: 14.6334 || 1.0814s/step\n",
            "step:30/314 || Total Loss: 12.7766 || 1.0823s/step\n",
            "step:40/314 || Total Loss: 12.3528 || 1.0391s/step\n",
            "step:50/314 || Total Loss: 11.9869 || 1.0411s/step\n",
            "step:60/314 || Total Loss: 11.2336 || 1.0563s/step\n",
            "step:70/314 || Total Loss: 10.8610 || 1.0467s/step\n",
            "step:80/314 || Total Loss: 11.4201 || 1.1851s/step\n",
            "step:90/314 || Total Loss: 11.5998 || 1.0608s/step\n",
            "step:100/314 || Total Loss: 11.9030 || 1.0553s/step\n",
            "step:110/314 || Total Loss: 12.5955 || 1.0019s/step\n",
            "step:120/314 || Total Loss: 12.0408 || 0.9700s/step\n",
            "step:130/314 || Total Loss: 11.5769 || 1.0600s/step\n",
            "step:140/314 || Total Loss: 11.9447 || 1.0853s/step\n",
            "step:150/314 || Total Loss: 11.6151 || 1.1633s/step\n",
            "step:160/314 || Total Loss: 11.6052 || 1.0710s/step\n",
            "step:170/314 || Total Loss: 11.4987 || 1.1929s/step\n",
            "step:180/314 || Total Loss: 11.2675 || 1.0264s/step\n",
            "step:190/314 || Total Loss: 11.0419 || 1.1042s/step\n",
            "step:200/314 || Total Loss: 10.8678 || 0.9842s/step\n",
            "step:210/314 || Total Loss: 11.1455 || 1.1719s/step\n",
            "step:220/314 || Total Loss: 11.8795 || 1.0729s/step\n",
            "step:230/314 || Total Loss: 11.6654 || 1.0362s/step\n",
            "step:240/314 || Total Loss: 11.4835 || 1.0645s/step\n",
            "step:250/314 || Total Loss: 11.6252 || 1.0854s/step\n",
            "step:260/314 || Total Loss: 11.6726 || 1.2321s/step\n",
            "step:270/314 || Total Loss: 12.6452 || 0.9891s/step\n",
            "step:280/314 || Total Loss: 12.4330 || 1.0307s/step\n",
            "step:290/314 || Total Loss: 12.4264 || 1.0728s/step\n",
            "step:300/314 || Total Loss: 12.2725 || 1.0412s/step\n",
            "step:310/314 || Total Loss: 12.9421 || 1.2313s/step\n",
            "Finish Training.\n",
            "Total Loss: 12.7750 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:34/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 2.2043 || 1.0601s/step\n",
            "step:10/314 || Total Loss: 3.6814 || 1.1139s/step\n",
            "step:20/314 || Total Loss: 5.4333 || 1.1881s/step\n",
            "step:30/314 || Total Loss: 6.4086 || 1.0817s/step\n",
            "step:40/314 || Total Loss: 6.9901 || 1.2856s/step\n",
            "step:50/314 || Total Loss: 7.3516 || 1.0843s/step\n",
            "step:60/314 || Total Loss: 8.2728 || 1.0584s/step\n",
            "step:70/314 || Total Loss: 8.2157 || 1.1324s/step\n",
            "step:80/314 || Total Loss: 8.1026 || 1.0874s/step\n",
            "step:90/314 || Total Loss: 7.7988 || 1.1906s/step\n",
            "step:100/314 || Total Loss: 7.7976 || 1.0969s/step\n",
            "step:110/314 || Total Loss: 8.0965 || 1.1166s/step\n",
            "step:120/314 || Total Loss: 8.1470 || 1.1291s/step\n",
            "step:130/314 || Total Loss: 8.2639 || 1.1159s/step\n",
            "step:140/314 || Total Loss: 9.0947 || 1.3755s/step\n",
            "step:150/314 || Total Loss: 8.7974 || 1.2604s/step\n",
            "step:160/314 || Total Loss: 9.1766 || 1.1465s/step\n",
            "step:170/314 || Total Loss: 8.9777 || 1.0051s/step\n",
            "step:180/314 || Total Loss: 9.4558 || 1.1340s/step\n",
            "step:190/314 || Total Loss: 9.4491 || 1.1805s/step\n",
            "step:200/314 || Total Loss: 9.4387 || 1.1762s/step\n",
            "step:210/314 || Total Loss: 9.8418 || 1.1817s/step\n",
            "step:220/314 || Total Loss: 9.7861 || 1.0765s/step\n",
            "step:230/314 || Total Loss: 9.5962 || 1.0505s/step\n",
            "step:240/314 || Total Loss: 9.4311 || 1.1151s/step\n",
            "step:250/314 || Total Loss: 9.2668 || 1.1418s/step\n",
            "step:260/314 || Total Loss: 9.1847 || 1.0067s/step\n",
            "step:270/314 || Total Loss: 9.4367 || 0.9036s/step\n",
            "step:280/314 || Total Loss: 9.9530 || 1.5260s/step\n",
            "step:290/314 || Total Loss: 9.8842 || 1.0073s/step\n",
            "step:300/314 || Total Loss: 9.7576 || 1.1194s/step\n",
            "step:310/314 || Total Loss: 9.8177 || 1.1046s/step\n",
            "Finish Training.\n",
            "Total Loss: 9.7462 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:35/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 20.7632 || 1.1188s/step\n",
            "step:10/314 || Total Loss: 11.5396 || 1.1742s/step\n",
            "step:20/314 || Total Loss: 8.4926 || 1.0168s/step\n",
            "step:30/314 || Total Loss: 8.3503 || 0.9539s/step\n",
            "step:40/314 || Total Loss: 11.3638 || 1.0062s/step\n",
            "step:50/314 || Total Loss: 11.0693 || 1.2438s/step\n",
            "step:60/314 || Total Loss: 10.6851 || 1.0576s/step\n",
            "step:70/314 || Total Loss: 11.1595 || 0.9743s/step\n",
            "step:80/314 || Total Loss: 10.7356 || 1.0635s/step\n",
            "step:90/314 || Total Loss: 10.9041 || 1.1780s/step\n",
            "step:100/314 || Total Loss: 11.2976 || 1.1839s/step\n",
            "step:110/314 || Total Loss: 11.3006 || 1.1419s/step\n",
            "step:120/314 || Total Loss: 11.2680 || 0.9323s/step\n",
            "step:130/314 || Total Loss: 11.8075 || 1.2693s/step\n",
            "step:140/314 || Total Loss: 11.7015 || 1.0745s/step\n",
            "step:150/314 || Total Loss: 11.5153 || 1.0701s/step\n",
            "step:160/314 || Total Loss: 11.4748 || 1.2111s/step\n",
            "step:170/314 || Total Loss: 11.6265 || 1.0298s/step\n",
            "step:180/314 || Total Loss: 11.9580 || 1.0511s/step\n",
            "step:190/314 || Total Loss: 11.8064 || 1.1300s/step\n",
            "step:200/314 || Total Loss: 12.7318 || 1.0359s/step\n",
            "step:210/314 || Total Loss: 13.1794 || 1.4065s/step\n",
            "step:220/314 || Total Loss: 13.3000 || 1.0367s/step\n",
            "step:230/314 || Total Loss: 12.9903 || 1.0017s/step\n",
            "step:240/314 || Total Loss: 12.7404 || 1.0136s/step\n",
            "step:250/314 || Total Loss: 12.5911 || 1.1059s/step\n",
            "step:260/314 || Total Loss: 12.4577 || 0.9417s/step\n",
            "step:270/314 || Total Loss: 12.6309 || 1.1763s/step\n",
            "step:280/314 || Total Loss: 12.5997 || 1.2750s/step\n",
            "step:290/314 || Total Loss: 12.3669 || 1.0534s/step\n",
            "step:300/314 || Total Loss: 12.1767 || 1.0582s/step\n",
            "step:310/314 || Total Loss: 12.1328 || 1.0515s/step\n",
            "Finish Training.\n",
            "Total Loss: 12.0392 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:36/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 12.4750 || 1.0327s/step\n",
            "step:10/314 || Total Loss: 23.1389 || 1.2529s/step\n",
            "step:20/314 || Total Loss: 16.7063 || 1.1311s/step\n",
            "step:30/314 || Total Loss: 14.3795 || 0.9805s/step\n",
            "step:40/314 || Total Loss: 12.8742 || 1.1387s/step\n",
            "step:50/314 || Total Loss: 11.4126 || 1.0973s/step\n",
            "step:60/314 || Total Loss: 11.5275 || 1.2187s/step\n",
            "step:70/314 || Total Loss: 10.8489 || 1.0497s/step\n",
            "step:80/314 || Total Loss: 10.7146 || 0.9605s/step\n",
            "step:90/314 || Total Loss: 10.1098 || 1.0789s/step\n",
            "step:100/314 || Total Loss: 10.5641 || 1.0206s/step\n",
            "step:110/314 || Total Loss: 10.6503 || 1.1760s/step\n",
            "step:120/314 || Total Loss: 10.3116 || 1.0761s/step\n",
            "step:130/314 || Total Loss: 10.3870 || 0.9777s/step\n",
            "step:140/314 || Total Loss: 10.1811 || 1.0407s/step\n",
            "step:150/314 || Total Loss: 9.9130 || 0.9906s/step\n",
            "step:160/314 || Total Loss: 9.9832 || 1.1597s/step\n",
            "step:170/314 || Total Loss: 10.1546 || 1.2077s/step\n",
            "step:180/314 || Total Loss: 9.8827 || 1.0322s/step\n",
            "step:190/314 || Total Loss: 9.8532 || 1.0422s/step\n",
            "step:200/314 || Total Loss: 9.7923 || 0.9810s/step\n",
            "step:210/314 || Total Loss: 9.7556 || 1.0210s/step\n",
            "step:220/314 || Total Loss: 9.6745 || 0.9489s/step\n",
            "step:230/314 || Total Loss: 9.7943 || 1.0553s/step\n",
            "step:240/314 || Total Loss: 9.5902 || 1.0887s/step\n",
            "step:250/314 || Total Loss: 9.5392 || 1.1402s/step\n",
            "step:260/314 || Total Loss: 9.7225 || 1.1195s/step\n",
            "step:270/314 || Total Loss: 9.9664 || 1.0882s/step\n",
            "step:280/314 || Total Loss: 9.8810 || 0.9913s/step\n",
            "step:290/314 || Total Loss: 9.9026 || 0.9888s/step\n",
            "step:300/314 || Total Loss: 10.2089 || 1.0462s/step\n",
            "step:310/314 || Total Loss: 10.4318 || 1.0837s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.3709 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:37/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 7.8205 || 1.1790s/step\n",
            "step:10/314 || Total Loss: 10.6520 || 1.1154s/step\n",
            "step:20/314 || Total Loss: 7.6120 || 1.0604s/step\n",
            "step:30/314 || Total Loss: 7.3623 || 1.0211s/step\n",
            "step:40/314 || Total Loss: 6.5336 || 0.9773s/step\n",
            "step:50/314 || Total Loss: 7.3651 || 1.0928s/step\n",
            "step:60/314 || Total Loss: 7.4022 || 1.0059s/step\n",
            "step:70/314 || Total Loss: 8.1321 || 1.0950s/step\n",
            "step:80/314 || Total Loss: 10.4871 || 1.1842s/step\n",
            "step:90/314 || Total Loss: 10.2043 || 1.1258s/step\n",
            "step:100/314 || Total Loss: 10.3676 || 1.1932s/step\n",
            "step:110/314 || Total Loss: 10.5399 || 1.0100s/step\n",
            "step:120/314 || Total Loss: 9.9471 || 0.9704s/step\n",
            "step:130/314 || Total Loss: 11.0027 || 1.1080s/step\n",
            "step:140/314 || Total Loss: 10.5244 || 1.0927s/step\n",
            "step:150/314 || Total Loss: 10.5038 || 1.1384s/step\n",
            "step:160/314 || Total Loss: 11.1777 || 1.0847s/step\n",
            "step:170/314 || Total Loss: 10.9597 || 1.1765s/step\n",
            "step:180/314 || Total Loss: 10.8568 || 0.9820s/step\n",
            "step:190/314 || Total Loss: 10.8850 || 1.0561s/step\n",
            "step:200/314 || Total Loss: 10.7554 || 1.0220s/step\n",
            "step:210/314 || Total Loss: 10.5491 || 0.9809s/step\n",
            "step:220/314 || Total Loss: 10.2923 || 1.1586s/step\n",
            "step:230/314 || Total Loss: 10.3201 || 1.2287s/step\n",
            "step:240/314 || Total Loss: 10.4495 || 0.9765s/step\n",
            "step:250/314 || Total Loss: 10.8230 || 1.0143s/step\n",
            "step:260/314 || Total Loss: 10.6406 || 0.9606s/step\n",
            "step:270/314 || Total Loss: 10.6590 || 1.0267s/step\n",
            "step:280/314 || Total Loss: 10.5172 || 0.9130s/step\n",
            "step:290/314 || Total Loss: 10.7790 || 1.1270s/step\n",
            "step:300/314 || Total Loss: 10.8150 || 1.0750s/step\n",
            "step:310/314 || Total Loss: 10.6371 || 1.0111s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.5163 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:38/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 6.7802 || 1.1076s/step\n",
            "step:10/314 || Total Loss: 17.3561 || 0.9451s/step\n",
            "step:20/314 || Total Loss: 12.2867 || 1.0562s/step\n",
            "step:30/314 || Total Loss: 10.8400 || 0.9646s/step\n",
            "step:40/314 || Total Loss: 9.6747 || 1.1203s/step\n",
            "step:50/314 || Total Loss: 10.0287 || 1.0493s/step\n",
            "step:60/314 || Total Loss: 11.4355 || 1.5236s/step\n",
            "step:70/314 || Total Loss: 15.6330 || 1.0324s/step\n",
            "step:80/314 || Total Loss: 14.7743 || 1.0069s/step\n",
            "step:90/314 || Total Loss: 13.9525 || 1.1719s/step\n",
            "step:100/314 || Total Loss: 13.6551 || 1.0028s/step\n",
            "step:110/314 || Total Loss: 14.7025 || 1.0215s/step\n",
            "step:120/314 || Total Loss: 14.4906 || 0.8295s/step\n",
            "step:130/314 || Total Loss: 14.0585 || 1.0007s/step\n",
            "step:140/314 || Total Loss: 13.3759 || 1.0646s/step\n",
            "step:150/314 || Total Loss: 13.8818 || 0.9696s/step\n",
            "step:160/314 || Total Loss: 13.2944 || 1.0593s/step\n",
            "step:170/314 || Total Loss: 12.9206 || 0.9285s/step\n",
            "step:180/314 || Total Loss: 12.4472 || 0.9509s/step\n",
            "step:190/314 || Total Loss: 12.2797 || 1.0764s/step\n",
            "step:200/314 || Total Loss: 11.8541 || 0.9932s/step\n",
            "step:210/314 || Total Loss: 11.9115 || 1.0237s/step\n",
            "step:220/314 || Total Loss: 12.3994 || 1.1021s/step\n",
            "step:230/314 || Total Loss: 13.0227 || 1.0386s/step\n",
            "step:240/314 || Total Loss: 13.0820 || 1.0817s/step\n",
            "step:250/314 || Total Loss: 13.1775 || 0.9954s/step\n",
            "step:260/314 || Total Loss: 13.3838 || 1.0308s/step\n",
            "step:270/314 || Total Loss: 13.1386 || 1.0024s/step\n",
            "step:280/314 || Total Loss: 13.0529 || 1.2376s/step\n",
            "step:290/314 || Total Loss: 12.7696 || 1.0468s/step\n",
            "step:300/314 || Total Loss: 12.5983 || 0.9929s/step\n",
            "step:310/314 || Total Loss: 13.2032 || 0.9789s/step\n",
            "Finish Training.\n",
            "Total Loss: 13.0169 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:39/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 2.8574 || 0.9644s/step\n",
            "step:10/314 || Total Loss: 18.1686 || 1.2075s/step\n",
            "step:20/314 || Total Loss: 13.2602 || 1.0905s/step\n",
            "step:30/314 || Total Loss: 13.3210 || 1.0070s/step\n",
            "step:40/314 || Total Loss: 11.6073 || 1.0562s/step\n",
            "step:50/314 || Total Loss: 11.3372 || 1.0296s/step\n",
            "step:60/314 || Total Loss: 10.3992 || 1.1525s/step\n",
            "step:70/314 || Total Loss: 10.8380 || 1.1218s/step\n",
            "step:80/314 || Total Loss: 10.6206 || 1.1265s/step\n",
            "step:90/314 || Total Loss: 10.0838 || 1.0208s/step\n",
            "step:100/314 || Total Loss: 10.4676 || 0.9959s/step\n",
            "step:110/314 || Total Loss: 10.5650 || 1.1308s/step\n",
            "step:120/314 || Total Loss: 11.3069 || 0.9749s/step\n",
            "step:130/314 || Total Loss: 10.8552 || 1.0754s/step\n",
            "step:140/314 || Total Loss: 10.6723 || 1.1349s/step\n",
            "step:150/314 || Total Loss: 11.1344 || 0.9648s/step\n",
            "step:160/314 || Total Loss: 10.8193 || 1.0957s/step\n",
            "step:170/314 || Total Loss: 10.5176 || 1.0012s/step\n",
            "step:180/314 || Total Loss: 10.2398 || 0.9374s/step\n",
            "step:190/314 || Total Loss: 10.3932 || 1.0235s/step\n",
            "step:200/314 || Total Loss: 10.5609 || 1.1723s/step\n",
            "step:210/314 || Total Loss: 10.3742 || 1.0058s/step\n",
            "step:220/314 || Total Loss: 10.1292 || 1.2527s/step\n",
            "step:230/314 || Total Loss: 9.9466 || 0.9512s/step\n",
            "step:240/314 || Total Loss: 10.2996 || 1.3745s/step\n",
            "step:250/314 || Total Loss: 10.2749 || 1.0339s/step\n",
            "step:260/314 || Total Loss: 11.5576 || 1.4593s/step\n",
            "step:270/314 || Total Loss: 11.5520 || 0.9804s/step\n",
            "step:280/314 || Total Loss: 11.4354 || 1.0523s/step\n",
            "step:290/314 || Total Loss: 11.2918 || 1.0365s/step\n",
            "step:300/314 || Total Loss: 11.0681 || 1.1908s/step\n",
            "step:310/314 || Total Loss: 10.8389 || 0.9751s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.8271 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:40/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 26.0249 || 1.2344s/step\n",
            "step:10/314 || Total Loss: 12.7589 || 1.0793s/step\n",
            "step:20/314 || Total Loss: 9.1788 || 0.9872s/step\n",
            "step:30/314 || Total Loss: 9.4528 || 1.1821s/step\n",
            "step:40/314 || Total Loss: 8.4994 || 0.9393s/step\n",
            "step:50/314 || Total Loss: 8.1019 || 1.0788s/step\n",
            "step:60/314 || Total Loss: 11.6068 || 1.0988s/step\n",
            "step:70/314 || Total Loss: 11.1078 || 1.1035s/step\n",
            "step:80/314 || Total Loss: 10.4872 || 1.0972s/step\n",
            "step:90/314 || Total Loss: 10.4294 || 1.1785s/step\n",
            "step:100/314 || Total Loss: 11.0181 || 1.0506s/step\n",
            "step:110/314 || Total Loss: 11.3725 || 1.1948s/step\n",
            "step:120/314 || Total Loss: 10.9654 || 1.1130s/step\n",
            "step:130/314 || Total Loss: 11.4273 || 1.0500s/step\n",
            "step:140/314 || Total Loss: 11.3138 || 1.3842s/step\n",
            "step:150/314 || Total Loss: 11.0266 || 1.0794s/step\n",
            "step:160/314 || Total Loss: 11.1703 || 1.0484s/step\n",
            "step:170/314 || Total Loss: 10.9683 || 0.9641s/step\n",
            "step:180/314 || Total Loss: 10.8137 || 1.0710s/step\n",
            "step:190/314 || Total Loss: 10.5317 || 1.3038s/step\n",
            "step:200/314 || Total Loss: 10.2670 || 1.0644s/step\n",
            "step:210/314 || Total Loss: 10.4313 || 1.2600s/step\n",
            "step:220/314 || Total Loss: 10.9130 || 1.2057s/step\n",
            "step:230/314 || Total Loss: 10.7558 || 1.0782s/step\n",
            "step:240/314 || Total Loss: 11.1261 || 1.2146s/step\n",
            "step:250/314 || Total Loss: 11.2792 || 1.0474s/step\n",
            "step:260/314 || Total Loss: 11.2894 || 1.1306s/step\n",
            "step:270/314 || Total Loss: 11.1221 || 1.1188s/step\n",
            "step:280/314 || Total Loss: 11.1577 || 0.9550s/step\n",
            "step:290/314 || Total Loss: 10.9036 || 0.9283s/step\n",
            "step:300/314 || Total Loss: 11.2036 || 1.1376s/step\n",
            "step:310/314 || Total Loss: 11.0451 || 1.0093s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.9129 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:41/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 2.2243 || 1.0301s/step\n",
            "step:10/314 || Total Loss: 17.0514 || 1.0406s/step\n",
            "step:20/314 || Total Loss: 14.9769 || 0.9605s/step\n",
            "step:30/314 || Total Loss: 15.3633 || 1.2050s/step\n",
            "step:40/314 || Total Loss: 16.7823 || 1.0976s/step\n",
            "step:50/314 || Total Loss: 17.0463 || 1.1288s/step\n",
            "step:60/314 || Total Loss: 15.4641 || 1.0975s/step\n",
            "step:70/314 || Total Loss: 15.4036 || 1.1082s/step\n",
            "step:80/314 || Total Loss: 13.8465 || 1.0928s/step\n",
            "step:90/314 || Total Loss: 12.9257 || 0.8945s/step\n",
            "step:100/314 || Total Loss: 12.5734 || 0.9916s/step\n",
            "step:110/314 || Total Loss: 12.4423 || 1.6116s/step\n",
            "step:120/314 || Total Loss: 12.2349 || 0.9916s/step\n",
            "step:130/314 || Total Loss: 12.5429 || 1.1174s/step\n",
            "step:140/314 || Total Loss: 12.0883 || 1.1695s/step\n",
            "step:150/314 || Total Loss: 11.6279 || 1.0226s/step\n",
            "step:160/314 || Total Loss: 11.2847 || 1.0897s/step\n",
            "step:170/314 || Total Loss: 10.9802 || 1.1602s/step\n",
            "step:180/314 || Total Loss: 10.6238 || 1.0707s/step\n",
            "step:190/314 || Total Loss: 10.5884 || 1.1104s/step\n",
            "step:200/314 || Total Loss: 10.5420 || 1.4133s/step\n",
            "step:210/314 || Total Loss: 10.3823 || 1.1573s/step\n",
            "step:220/314 || Total Loss: 10.6084 || 1.0590s/step\n",
            "step:230/314 || Total Loss: 10.9821 || 1.1521s/step\n",
            "step:240/314 || Total Loss: 10.7250 || 0.9952s/step\n",
            "step:250/314 || Total Loss: 10.7000 || 1.1582s/step\n",
            "step:260/314 || Total Loss: 10.4686 || 1.0495s/step\n",
            "step:270/314 || Total Loss: 10.4225 || 1.0557s/step\n",
            "step:280/314 || Total Loss: 10.1742 || 1.0028s/step\n",
            "step:290/314 || Total Loss: 10.2575 || 1.1693s/step\n",
            "step:300/314 || Total Loss: 10.6735 || 1.1283s/step\n",
            "step:310/314 || Total Loss: 11.1120 || 1.0781s/step\n",
            "Finish Training.\n",
            "Total Loss: 11.0719 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:42/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 9.0156 || 1.0701s/step\n",
            "step:10/314 || Total Loss: 11.7706 || 1.1154s/step\n",
            "step:20/314 || Total Loss: 14.4828 || 1.0813s/step\n",
            "step:30/314 || Total Loss: 11.2674 || 0.9792s/step\n",
            "step:40/314 || Total Loss: 12.2104 || 1.0822s/step\n",
            "step:50/314 || Total Loss: 11.1893 || 1.0088s/step\n",
            "step:60/314 || Total Loss: 12.4155 || 1.1128s/step\n",
            "step:70/314 || Total Loss: 12.9370 || 1.1827s/step\n",
            "step:80/314 || Total Loss: 12.4543 || 1.0336s/step\n",
            "step:90/314 || Total Loss: 12.2678 || 1.3565s/step\n",
            "step:100/314 || Total Loss: 12.7538 || 1.0747s/step\n",
            "step:110/314 || Total Loss: 12.4746 || 1.1891s/step\n",
            "step:120/314 || Total Loss: 12.3940 || 1.1684s/step\n",
            "step:130/314 || Total Loss: 12.2487 || 0.9755s/step\n",
            "step:140/314 || Total Loss: 12.3068 || 1.2410s/step\n",
            "step:150/314 || Total Loss: 12.6851 || 1.3086s/step\n",
            "step:160/314 || Total Loss: 12.2487 || 1.0403s/step\n",
            "step:170/314 || Total Loss: 11.8823 || 1.0722s/step\n",
            "step:180/314 || Total Loss: 11.3797 || 1.1212s/step\n",
            "step:190/314 || Total Loss: 11.0918 || 1.1393s/step\n",
            "step:200/314 || Total Loss: 10.7838 || 1.0290s/step\n",
            "step:210/314 || Total Loss: 10.5432 || 1.0735s/step\n",
            "step:220/314 || Total Loss: 10.3659 || 1.3671s/step\n",
            "step:230/314 || Total Loss: 10.2258 || 0.9666s/step\n",
            "step:240/314 || Total Loss: 10.8031 || 1.5250s/step\n",
            "step:250/314 || Total Loss: 10.8383 || 1.0203s/step\n",
            "step:260/314 || Total Loss: 10.6594 || 1.0210s/step\n",
            "step:270/314 || Total Loss: 10.7682 || 1.0085s/step\n",
            "step:280/314 || Total Loss: 10.7110 || 1.0858s/step\n",
            "step:290/314 || Total Loss: 10.8435 || 1.0608s/step\n",
            "step:300/314 || Total Loss: 10.7369 || 1.0751s/step\n",
            "step:310/314 || Total Loss: 10.5950 || 1.0723s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.5231 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:43/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 5.2628 || 1.0147s/step\n",
            "step:10/314 || Total Loss: 8.6291 || 1.3411s/step\n",
            "step:20/314 || Total Loss: 10.4087 || 1.0200s/step\n",
            "step:30/314 || Total Loss: 10.9039 || 1.0675s/step\n",
            "step:40/314 || Total Loss: 9.9013 || 1.0749s/step\n",
            "step:50/314 || Total Loss: 9.0741 || 1.0753s/step\n",
            "step:60/314 || Total Loss: 8.4648 || 1.3542s/step\n",
            "step:70/314 || Total Loss: 8.4889 || 1.5396s/step\n",
            "step:80/314 || Total Loss: 7.9780 || 0.9822s/step\n",
            "step:90/314 || Total Loss: 8.0766 || 1.0065s/step\n",
            "step:100/314 || Total Loss: 7.8529 || 1.0261s/step\n",
            "step:110/314 || Total Loss: 7.9525 || 1.0015s/step\n",
            "step:120/314 || Total Loss: 7.5917 || 1.1690s/step\n",
            "step:130/314 || Total Loss: 8.0613 || 0.9918s/step\n",
            "step:140/314 || Total Loss: 7.9224 || 1.0032s/step\n",
            "step:150/314 || Total Loss: 7.8423 || 1.1583s/step\n",
            "step:160/314 || Total Loss: 7.5486 || 1.0723s/step\n",
            "step:170/314 || Total Loss: 7.4693 || 1.0535s/step\n",
            "step:180/314 || Total Loss: 7.2272 || 0.9976s/step\n",
            "step:190/314 || Total Loss: 7.3863 || 1.1209s/step\n",
            "step:200/314 || Total Loss: 7.5177 || 1.0894s/step\n",
            "step:210/314 || Total Loss: 7.5415 || 1.0845s/step\n",
            "step:220/314 || Total Loss: 7.5725 || 1.1050s/step\n",
            "step:230/314 || Total Loss: 7.4924 || 1.0730s/step\n",
            "step:240/314 || Total Loss: 7.6871 || 1.0446s/step\n",
            "step:250/314 || Total Loss: 7.6036 || 1.1339s/step\n",
            "step:260/314 || Total Loss: 7.6410 || 1.0635s/step\n",
            "step:270/314 || Total Loss: 7.5519 || 0.9324s/step\n",
            "step:280/314 || Total Loss: 8.1871 || 0.9857s/step\n",
            "step:290/314 || Total Loss: 8.0720 || 1.1585s/step\n",
            "step:300/314 || Total Loss: 8.1151 || 1.2536s/step\n",
            "step:310/314 || Total Loss: 7.9843 || 1.0270s/step\n",
            "Finish Training.\n",
            "Total Loss: 8.0898 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:44/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 4.1669 || 1.1126s/step\n",
            "step:10/314 || Total Loss: 9.6138 || 1.1262s/step\n",
            "step:20/314 || Total Loss: 15.9755 || 1.2526s/step\n",
            "step:30/314 || Total Loss: 16.2773 || 1.2271s/step\n",
            "step:40/314 || Total Loss: 13.6750 || 1.0758s/step\n",
            "step:50/314 || Total Loss: 13.5186 || 0.9621s/step\n",
            "step:60/314 || Total Loss: 12.9466 || 1.0200s/step\n",
            "step:70/314 || Total Loss: 12.3349 || 1.1501s/step\n",
            "step:80/314 || Total Loss: 12.8181 || 1.2389s/step\n",
            "step:90/314 || Total Loss: 12.5269 || 1.0860s/step\n",
            "step:100/314 || Total Loss: 11.8696 || 1.0113s/step\n",
            "step:110/314 || Total Loss: 11.3159 || 1.0253s/step\n",
            "step:120/314 || Total Loss: 11.5334 || 0.9195s/step\n",
            "step:130/314 || Total Loss: 11.0103 || 1.6068s/step\n",
            "step:140/314 || Total Loss: 10.6872 || 0.9639s/step\n",
            "step:150/314 || Total Loss: 10.7164 || 1.0382s/step\n",
            "step:160/314 || Total Loss: 11.9122 || 1.1091s/step\n",
            "step:170/314 || Total Loss: 12.5385 || 1.0225s/step\n",
            "step:180/314 || Total Loss: 12.0139 || 1.0712s/step\n",
            "step:190/314 || Total Loss: 11.6376 || 1.2345s/step\n",
            "step:200/314 || Total Loss: 11.5041 || 1.0020s/step\n",
            "step:210/314 || Total Loss: 11.1111 || 1.1010s/step\n",
            "step:220/314 || Total Loss: 11.4738 || 1.1285s/step\n",
            "step:230/314 || Total Loss: 11.1899 || 1.1536s/step\n",
            "step:240/314 || Total Loss: 11.1006 || 1.1151s/step\n",
            "step:250/314 || Total Loss: 10.9388 || 1.0010s/step\n",
            "step:260/314 || Total Loss: 10.8273 || 0.9663s/step\n",
            "step:270/314 || Total Loss: 10.7342 || 0.9898s/step\n",
            "step:280/314 || Total Loss: 10.7603 || 0.9932s/step\n",
            "step:290/314 || Total Loss: 10.6128 || 1.3430s/step\n",
            "step:300/314 || Total Loss: 10.4406 || 0.9587s/step\n",
            "step:310/314 || Total Loss: 10.4643 || 0.9594s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.5151 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:45/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 9.6971 || 1.0347s/step\n",
            "step:10/314 || Total Loss: 8.0441 || 1.1440s/step\n",
            "step:20/314 || Total Loss: 13.0455 || 1.0870s/step\n",
            "step:30/314 || Total Loss: 10.4745 || 1.0980s/step\n",
            "step:40/314 || Total Loss: 14.0451 || 1.0035s/step\n",
            "step:50/314 || Total Loss: 16.0223 || 1.0574s/step\n",
            "step:60/314 || Total Loss: 14.8264 || 0.9660s/step\n",
            "step:70/314 || Total Loss: 15.9186 || 1.3770s/step\n",
            "step:80/314 || Total Loss: 15.6086 || 1.3450s/step\n",
            "step:90/314 || Total Loss: 14.7314 || 1.0056s/step\n",
            "step:100/314 || Total Loss: 13.8598 || 0.9041s/step\n",
            "step:110/314 || Total Loss: 12.9965 || 1.0077s/step\n",
            "step:120/314 || Total Loss: 12.5225 || 0.9812s/step\n",
            "step:130/314 || Total Loss: 12.0386 || 1.1145s/step\n",
            "step:140/314 || Total Loss: 11.8158 || 1.0368s/step\n",
            "step:150/314 || Total Loss: 11.4839 || 0.9624s/step\n",
            "step:160/314 || Total Loss: 11.4113 || 1.0648s/step\n",
            "step:170/314 || Total Loss: 11.0101 || 1.1316s/step\n",
            "step:180/314 || Total Loss: 11.0667 || 1.1754s/step\n",
            "step:190/314 || Total Loss: 10.7166 || 1.0044s/step\n",
            "step:200/314 || Total Loss: 10.9711 || 1.0026s/step\n",
            "step:210/314 || Total Loss: 10.6971 || 1.0111s/step\n",
            "step:220/314 || Total Loss: 10.5107 || 1.3651s/step\n",
            "step:230/314 || Total Loss: 10.5197 || 1.0936s/step\n",
            "step:240/314 || Total Loss: 10.2647 || 1.1033s/step\n",
            "step:250/314 || Total Loss: 9.9654 || 1.0223s/step\n",
            "step:260/314 || Total Loss: 9.8000 || 1.2807s/step\n",
            "step:270/314 || Total Loss: 9.9200 || 1.1999s/step\n",
            "step:280/314 || Total Loss: 10.0109 || 1.0809s/step\n",
            "step:290/314 || Total Loss: 10.1057 || 1.1673s/step\n",
            "step:300/314 || Total Loss: 10.2423 || 1.2374s/step\n",
            "step:310/314 || Total Loss: 10.1902 || 1.0186s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.1518 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:46/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 5.6829 || 1.0571s/step\n",
            "step:10/314 || Total Loss: 5.2980 || 1.0866s/step\n",
            "step:20/314 || Total Loss: 8.9084 || 1.2720s/step\n",
            "step:30/314 || Total Loss: 9.1927 || 1.0797s/step\n",
            "step:40/314 || Total Loss: 8.0489 || 1.0162s/step\n",
            "step:50/314 || Total Loss: 7.2143 || 1.1527s/step\n",
            "step:60/314 || Total Loss: 8.3036 || 1.0360s/step\n",
            "step:70/314 || Total Loss: 7.9986 || 1.0242s/step\n",
            "step:80/314 || Total Loss: 7.7226 || 1.0054s/step\n",
            "step:90/314 || Total Loss: 8.0209 || 1.2216s/step\n",
            "step:100/314 || Total Loss: 8.5930 || 1.0984s/step\n",
            "step:110/314 || Total Loss: 8.1934 || 1.1050s/step\n",
            "step:120/314 || Total Loss: 8.1818 || 1.1381s/step\n",
            "step:130/314 || Total Loss: 8.1236 || 1.0992s/step\n",
            "step:140/314 || Total Loss: 7.9748 || 1.0662s/step\n",
            "step:150/314 || Total Loss: 8.1750 || 1.3320s/step\n",
            "step:160/314 || Total Loss: 8.1289 || 1.0143s/step\n",
            "step:170/314 || Total Loss: 8.1547 || 1.1467s/step\n",
            "step:180/314 || Total Loss: 8.3034 || 1.0071s/step\n",
            "step:190/314 || Total Loss: 8.3338 || 1.1360s/step\n",
            "step:200/314 || Total Loss: 8.1908 || 1.0096s/step\n",
            "step:210/314 || Total Loss: 8.3132 || 1.0060s/step\n",
            "step:220/314 || Total Loss: 8.5017 || 1.0783s/step\n",
            "step:230/314 || Total Loss: 8.3884 || 0.9636s/step\n",
            "step:240/314 || Total Loss: 8.4712 || 0.9762s/step\n",
            "step:250/314 || Total Loss: 8.4162 || 1.0896s/step\n",
            "step:260/314 || Total Loss: 8.3359 || 0.9896s/step\n",
            "step:270/314 || Total Loss: 8.6348 || 1.0779s/step\n",
            "step:280/314 || Total Loss: 8.6188 || 1.4033s/step\n",
            "step:290/314 || Total Loss: 8.9446 || 1.3070s/step\n",
            "step:300/314 || Total Loss: 8.7416 || 0.9923s/step\n",
            "step:310/314 || Total Loss: 8.8001 || 1.5955s/step\n",
            "Finish Training.\n",
            "Total Loss: 8.7290 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:47/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 35.2976 || 1.2919s/step\n",
            "step:10/314 || Total Loss: 20.6765 || 1.0883s/step\n",
            "step:20/314 || Total Loss: 14.3890 || 1.1947s/step\n",
            "step:30/314 || Total Loss: 11.0022 || 1.1045s/step\n",
            "step:40/314 || Total Loss: 9.7287 || 0.9886s/step\n",
            "step:50/314 || Total Loss: 10.1627 || 1.1252s/step\n",
            "step:60/314 || Total Loss: 9.1552 || 1.0821s/step\n",
            "step:70/314 || Total Loss: 8.9316 || 0.9605s/step\n",
            "step:80/314 || Total Loss: 8.4812 || 0.9883s/step\n",
            "step:90/314 || Total Loss: 8.2436 || 1.0534s/step\n",
            "step:100/314 || Total Loss: 8.0414 || 1.0071s/step\n",
            "step:110/314 || Total Loss: 7.9324 || 1.0996s/step\n",
            "step:120/314 || Total Loss: 7.8391 || 1.0544s/step\n",
            "step:130/314 || Total Loss: 7.8625 || 1.1221s/step\n",
            "step:140/314 || Total Loss: 7.9672 || 1.1046s/step\n",
            "step:150/314 || Total Loss: 9.6937 || 1.1355s/step\n",
            "step:160/314 || Total Loss: 10.1435 || 0.9692s/step\n",
            "step:170/314 || Total Loss: 9.9760 || 1.2754s/step\n",
            "step:180/314 || Total Loss: 9.9010 || 1.1420s/step\n",
            "step:190/314 || Total Loss: 9.9925 || 1.0745s/step\n",
            "step:200/314 || Total Loss: 9.7754 || 1.0091s/step\n",
            "step:210/314 || Total Loss: 9.7861 || 1.1261s/step\n",
            "step:220/314 || Total Loss: 10.5657 || 1.2463s/step\n",
            "step:230/314 || Total Loss: 10.3672 || 1.1927s/step\n",
            "step:240/314 || Total Loss: 10.1456 || 0.9211s/step\n",
            "step:250/314 || Total Loss: 10.4218 || 1.1381s/step\n",
            "step:260/314 || Total Loss: 10.2181 || 1.0291s/step\n",
            "step:270/314 || Total Loss: 10.1578 || 1.0023s/step\n",
            "step:280/314 || Total Loss: 10.4210 || 0.9353s/step\n",
            "step:290/314 || Total Loss: 10.2167 || 1.0283s/step\n",
            "step:300/314 || Total Loss: 10.0465 || 1.1419s/step\n",
            "step:310/314 || Total Loss: 10.1567 || 1.0024s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.0329 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:48/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 5.1933 || 1.0498s/step\n",
            "step:10/314 || Total Loss: 6.2998 || 0.9915s/step\n",
            "step:20/314 || Total Loss: 8.5137 || 1.0134s/step\n",
            "step:30/314 || Total Loss: 6.8110 || 1.0379s/step\n",
            "step:40/314 || Total Loss: 7.4600 || 1.0585s/step\n",
            "step:50/314 || Total Loss: 7.7594 || 1.1184s/step\n",
            "step:60/314 || Total Loss: 10.1819 || 1.0808s/step\n",
            "step:70/314 || Total Loss: 11.3207 || 1.0818s/step\n",
            "step:80/314 || Total Loss: 10.4675 || 0.9944s/step\n",
            "step:90/314 || Total Loss: 10.3720 || 0.9866s/step\n",
            "step:100/314 || Total Loss: 10.4931 || 0.8347s/step\n",
            "step:110/314 || Total Loss: 10.9842 || 1.1156s/step\n",
            "step:120/314 || Total Loss: 10.4914 || 1.0679s/step\n",
            "step:130/314 || Total Loss: 10.9790 || 1.0481s/step\n",
            "step:140/314 || Total Loss: 11.4135 || 1.5167s/step\n",
            "step:150/314 || Total Loss: 11.9834 || 1.0637s/step\n",
            "step:160/314 || Total Loss: 11.8193 || 1.0088s/step\n",
            "step:170/314 || Total Loss: 11.7817 || 1.1500s/step\n",
            "step:180/314 || Total Loss: 11.3942 || 1.7474s/step\n",
            "step:190/314 || Total Loss: 11.0427 || 1.0637s/step\n",
            "step:200/314 || Total Loss: 11.9767 || 1.4428s/step\n",
            "step:210/314 || Total Loss: 11.8685 || 1.1290s/step\n",
            "step:220/314 || Total Loss: 11.6046 || 1.1219s/step\n",
            "step:230/314 || Total Loss: 11.6114 || 1.0650s/step\n",
            "step:240/314 || Total Loss: 11.4522 || 0.9745s/step\n",
            "step:250/314 || Total Loss: 11.1507 || 1.0416s/step\n",
            "step:260/314 || Total Loss: 10.8776 || 0.9820s/step\n",
            "step:270/314 || Total Loss: 10.6149 || 1.0244s/step\n",
            "step:280/314 || Total Loss: 10.5734 || 1.0299s/step\n",
            "step:290/314 || Total Loss: 10.4731 || 1.0478s/step\n",
            "step:300/314 || Total Loss: 10.5060 || 1.1358s/step\n",
            "step:310/314 || Total Loss: 10.4726 || 1.2447s/step\n",
            "Finish Training.\n",
            "Total Loss: 10.4102 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:49/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 21.9084 || 1.1771s/step\n",
            "step:10/314 || Total Loss: 6.3773 || 1.0018s/step\n",
            "step:20/314 || Total Loss: 8.6292 || 1.0733s/step\n",
            "step:30/314 || Total Loss: 7.4795 || 0.9786s/step\n",
            "step:40/314 || Total Loss: 6.9946 || 1.1258s/step\n",
            "step:50/314 || Total Loss: 8.0423 || 1.0644s/step\n",
            "step:60/314 || Total Loss: 9.6558 || 1.0996s/step\n",
            "step:70/314 || Total Loss: 9.1890 || 1.1460s/step\n",
            "step:80/314 || Total Loss: 8.9308 || 1.2467s/step\n",
            "step:90/314 || Total Loss: 9.6520 || 1.3578s/step\n",
            "step:100/314 || Total Loss: 9.8308 || 1.1069s/step\n",
            "step:110/314 || Total Loss: 10.1504 || 1.3645s/step\n",
            "step:120/314 || Total Loss: 10.3424 || 1.1700s/step\n",
            "step:130/314 || Total Loss: 10.5553 || 1.2749s/step\n",
            "step:140/314 || Total Loss: 10.1333 || 1.0856s/step\n",
            "step:150/314 || Total Loss: 10.5155 || 1.0149s/step\n",
            "step:160/314 || Total Loss: 10.2020 || 0.9939s/step\n",
            "step:170/314 || Total Loss: 10.0571 || 1.1292s/step\n",
            "step:180/314 || Total Loss: 9.9241 || 1.2242s/step\n",
            "step:190/314 || Total Loss: 9.8232 || 1.0575s/step\n",
            "step:200/314 || Total Loss: 9.8553 || 1.2032s/step\n",
            "step:210/314 || Total Loss: 9.6018 || 1.0871s/step\n",
            "step:220/314 || Total Loss: 9.5818 || 1.1383s/step\n",
            "step:230/314 || Total Loss: 9.4331 || 0.9597s/step\n",
            "step:240/314 || Total Loss: 9.1980 || 1.1776s/step\n",
            "step:250/314 || Total Loss: 9.2053 || 1.1447s/step\n",
            "step:260/314 || Total Loss: 9.0372 || 1.0054s/step\n",
            "step:270/314 || Total Loss: 9.1444 || 1.0536s/step\n",
            "step:280/314 || Total Loss: 8.9861 || 1.0153s/step\n",
            "step:290/314 || Total Loss: 8.9436 || 1.0789s/step\n",
            "step:300/314 || Total Loss: 8.7928 || 0.9705s/step\n",
            "step:310/314 || Total Loss: 8.6864 || 1.0732s/step\n",
            "Finish Training.\n",
            "Total Loss: 8.6693 || Val Loss: 0.0000 \n",
            "\n",
            "----------Train one epoch.----------\n",
            "Epoch:50/50\n",
            "Start Training.\n",
            "step:1/314 || Total Loss: 6.0565 || 1.1063s/step\n",
            "step:10/314 || Total Loss: 5.5577 || 1.1642s/step\n",
            "step:20/314 || Total Loss: 11.8986 || 1.2640s/step\n",
            "step:30/314 || Total Loss: 9.6744 || 0.9365s/step\n",
            "step:40/314 || Total Loss: 9.5750 || 1.0875s/step\n",
            "step:50/314 || Total Loss: 8.7850 || 1.0370s/step\n",
            "step:60/314 || Total Loss: 9.5150 || 1.1168s/step\n",
            "step:70/314 || Total Loss: 9.5117 || 0.9704s/step\n",
            "step:80/314 || Total Loss: 8.8594 || 0.9844s/step\n",
            "step:90/314 || Total Loss: 8.5327 || 1.0446s/step\n",
            "step:100/314 || Total Loss: 8.6246 || 0.9712s/step\n",
            "step:110/314 || Total Loss: 9.7883 || 1.1230s/step\n",
            "step:120/314 || Total Loss: 9.4393 || 0.9975s/step\n",
            "step:130/314 || Total Loss: 9.0073 || 1.1498s/step\n",
            "step:140/314 || Total Loss: 8.5677 || 0.9774s/step\n",
            "step:150/314 || Total Loss: 8.7598 || 1.1195s/step\n",
            "step:160/314 || Total Loss: 9.1298 || 1.0568s/step\n",
            "step:170/314 || Total Loss: 9.1519 || 1.0515s/step\n",
            "step:180/314 || Total Loss: 9.1638 || 0.9661s/step\n",
            "step:190/314 || Total Loss: 9.1647 || 1.0380s/step\n",
            "step:200/314 || Total Loss: 9.4963 || 1.1118s/step\n",
            "step:210/314 || Total Loss: 9.5132 || 1.0877s/step\n",
            "step:220/314 || Total Loss: 9.3888 || 0.9882s/step\n",
            "step:230/314 || Total Loss: 9.1434 || 0.9100s/step\n",
            "step:240/314 || Total Loss: 9.1220 || 1.1567s/step\n",
            "step:250/314 || Total Loss: 9.2863 || 1.1010s/step\n",
            "step:260/314 || Total Loss: 9.1940 || 1.1426s/step\n",
            "step:270/314 || Total Loss: 9.4997 || 0.9921s/step\n",
            "step:280/314 || Total Loss: 9.3137 || 1.0012s/step\n",
            "step:290/314 || Total Loss: 9.1513 || 1.1114s/step\n",
            "step:300/314 || Total Loss: 9.3782 || 1.0594s/step\n",
            "step:310/314 || Total Loss: 9.8120 || 1.1072s/step\n",
            "Finish Training.\n",
            "Total Loss: 9.7055 || Val Loss: 0.0000 \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RY9f2L1zWfL7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}